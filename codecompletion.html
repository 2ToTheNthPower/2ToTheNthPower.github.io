<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=MSSLfUayeNh9PW3ng9UWrqPqkO_clMDF6VDWdjQbdvOB1rEp0mYKuioi9p9DCaL5');ol.lst-kix_list_7-0{list-style-type:none}.lst-kix_list_2-1>li{counter-increment:lst-ctn-kix_list_2-1}.lst-kix_list_21-8>li{counter-increment:lst-ctn-kix_list_21-8}ol.lst-kix_list_9-0.start{counter-reset:lst-ctn-kix_list_9-0 0}ol.lst-kix_list_13-4.start{counter-reset:lst-ctn-kix_list_13-4 0}.lst-kix_list_13-0>li{counter-increment:lst-ctn-kix_list_13-0}ol.lst-kix_list_20-2.start{counter-reset:lst-ctn-kix_list_20-2 0}.lst-kix_list_5-0>li{counter-increment:lst-ctn-kix_list_5-0}ol.lst-kix_list_2-3.start{counter-reset:lst-ctn-kix_list_2-3 0}ol.lst-kix_list_7-5{list-style-type:none}ol.lst-kix_list_7-6{list-style-type:none}ol.lst-kix_list_7-7{list-style-type:none}ol.lst-kix_list_7-8{list-style-type:none}ol.lst-kix_list_7-1{list-style-type:none}ol.lst-kix_list_7-2{list-style-type:none}ol.lst-kix_list_7-3{list-style-type:none}ol.lst-kix_list_7-4{list-style-type:none}ol.lst-kix_list_5-3.start{counter-reset:lst-ctn-kix_list_5-3 0}.lst-kix_list_4-3>li{counter-increment:lst-ctn-kix_list_4-3}ol.lst-kix_list_17-1.start{counter-reset:lst-ctn-kix_list_17-1 0}.lst-kix_list_18-8>li{counter-increment:lst-ctn-kix_list_18-8}ol.lst-kix_list_8-8.start{counter-reset:lst-ctn-kix_list_8-8 0}ol.lst-kix_list_10-4.start{counter-reset:lst-ctn-kix_list_10-4 0}.lst-kix_list_7-2>li{counter-increment:lst-ctn-kix_list_7-2}ol.lst-kix_list_16-5{list-style-type:none}.lst-kix_list_1-4>li{counter-increment:lst-ctn-kix_list_1-4}ol.lst-kix_list_16-6{list-style-type:none}ol.lst-kix_list_16-7{list-style-type:none}ol.lst-kix_list_1-6.start{counter-reset:lst-ctn-kix_list_1-6 0}ol.lst-kix_list_16-8{list-style-type:none}ol.lst-kix_list_9-5.start{counter-reset:lst-ctn-kix_list_9-5 0}ol.lst-kix_list_16-1{list-style-type:none}ol.lst-kix_list_16-2{list-style-type:none}ol.lst-kix_list_16-3{list-style-type:none}ol.lst-kix_list_16-4{list-style-type:none}ol.lst-kix_list_16-0{list-style-type:none}ol.lst-kix_list_20-7.start{counter-reset:lst-ctn-kix_list_20-7 0}.lst-kix_list_9-4>li{counter-increment:lst-ctn-kix_list_9-4}ol.lst-kix_list_16-4.start{counter-reset:lst-ctn-kix_list_16-4 0}ol.lst-kix_list_14-1.start{counter-reset:lst-ctn-kix_list_14-1 0}.lst-kix_list_6-5>li{counter-increment:lst-ctn-kix_list_6-5}.lst-kix_list_3-6>li{counter-increment:lst-ctn-kix_list_3-6}.lst-kix_list_2-8>li{counter-increment:lst-ctn-kix_list_2-8}ol.lst-kix_638crpolklom-1.start{counter-reset:lst-ctn-kix_638crpolklom-1 0}.lst-kix_list_8-6>li{counter-increment:lst-ctn-kix_list_8-6}ol.lst-kix_list_4-6.start{counter-reset:lst-ctn-kix_list_4-6 0}ol.lst-kix_list_9-7{list-style-type:none}ol.lst-kix_list_9-8{list-style-type:none}.lst-kix_81qdu2dxiajy-1>li{counter-increment:lst-ctn-kix_81qdu2dxiajy-1}ol.lst-kix_list_3-0.start{counter-reset:lst-ctn-kix_list_3-0 0}ol.lst-kix_list_9-3{list-style-type:none}ol.lst-kix_list_9-4{list-style-type:none}.lst-kix_list_5-7>li{counter-increment:lst-ctn-kix_list_5-7}ol.lst-kix_list_9-5{list-style-type:none}ol.lst-kix_list_9-6{list-style-type:none}ol.lst-kix_list_9-0{list-style-type:none}ol.lst-kix_list_9-1{list-style-type:none}ol.lst-kix_list_9-2{list-style-type:none}ol.lst-kix_81qdu2dxiajy-2.start{counter-reset:lst-ctn-kix_81qdu2dxiajy-2 0}.lst-kix_list_3-5>li{counter-increment:lst-ctn-kix_list_3-5}ol.lst-kix_list_1-1.start{counter-reset:lst-ctn-kix_list_1-1 0}ol.lst-kix_list_18-3.start{counter-reset:lst-ctn-kix_list_18-3 0}ol.lst-kix_wg014qgjj4p4-4.start{counter-reset:lst-ctn-kix_wg014qgjj4p4-4 0}ol.lst-kix_list_18-7{list-style-type:none}ol.lst-kix_list_18-8{list-style-type:none}ol.lst-kix_list_18-3{list-style-type:none}ol.lst-kix_list_18-4{list-style-type:none}.lst-kix_list_6-4>li{counter-increment:lst-ctn-kix_list_6-4}ol.lst-kix_list_18-5{list-style-type:none}ol.lst-kix_list_18-6{list-style-type:none}ol.lst-kix_list_18-0{list-style-type:none}ol.lst-kix_list_18-1{list-style-type:none}.lst-kix_list_9-3>li{counter-increment:lst-ctn-kix_list_9-3}ol.lst-kix_list_18-2{list-style-type:none}ol.lst-kix_list_15-2.start{counter-reset:lst-ctn-kix_list_15-2 0}ol.lst-kix_list_2-8.start{counter-reset:lst-ctn-kix_list_2-8 0}ol.lst-kix_list_7-6.start{counter-reset:lst-ctn-kix_list_7-6 0}ol.lst-kix_list_15-3.start{counter-reset:lst-ctn-kix_list_15-3 0}ol.lst-kix_list_5-8.start{counter-reset:lst-ctn-kix_list_5-8 0}.lst-kix_list_1-3>li{counter-increment:lst-ctn-kix_list_1-3}.lst-kix_wg014qgjj4p4-4>li{counter-increment:lst-ctn-kix_wg014qgjj4p4-4}ol.lst-kix_list_12-2.start{counter-reset:lst-ctn-kix_list_12-2 0}ol.lst-kix_list_6-0.start{counter-reset:lst-ctn-kix_list_6-0 0}.lst-kix_list_4-2>li{counter-increment:lst-ctn-kix_list_4-2}ol.lst-kix_list_3-1{list-style-type:none}ol.lst-kix_list_3-2{list-style-type:none}ol.lst-kix_81qdu2dxiajy-0{list-style-type:none}ol.lst-kix_list_3-3{list-style-type:none}ol.lst-kix_list_3-4.start{counter-reset:lst-ctn-kix_list_3-4 0}ol.lst-kix_81qdu2dxiajy-1{list-style-type:none}.lst-kix_k5epc2kusrs0-3>li:before{content:"\0025cf  "}.lst-kix_list_5-1>li{counter-increment:lst-ctn-kix_list_5-1}ol.lst-kix_list_3-4{list-style-type:none}ol.lst-kix_81qdu2dxiajy-2{list-style-type:none}ol.lst-kix_list_19-0.start{counter-reset:lst-ctn-kix_list_19-0 0}ol.lst-kix_list_21-3.start{counter-reset:lst-ctn-kix_list_21-3 0}ol.lst-kix_list_3-0{list-style-type:none}.lst-kix_k5epc2kusrs0-7>li:before{content:"\0025cb  "}.lst-kix_list_7-1>li{counter-increment:lst-ctn-kix_list_7-1}.lst-kix_k5epc2kusrs0-0>li:before{content:"\0025cf  "}.lst-kix_k5epc2kusrs0-8>li:before{content:"\0025a0  "}.lst-kix_list_21-8>li:before{content:"" counter(lst-ctn-kix_list_21-8,decimal) ". "}.lst-kix_list_16-0>li{counter-increment:lst-ctn-kix_list_16-0}.lst-kix_list_8-0>li{counter-increment:lst-ctn-kix_list_8-0}.lst-kix_list_10-0>li{counter-increment:lst-ctn-kix_list_10-0}ol.lst-kix_wg014qgjj4p4-0.start{counter-reset:lst-ctn-kix_wg014qgjj4p4-0 0}ol.lst-kix_list_18-2.start{counter-reset:lst-ctn-kix_list_18-2 0}ol.lst-kix_list_3-5{list-style-type:none}ol.lst-kix_list_3-6{list-style-type:none}ol.lst-kix_list_3-7{list-style-type:none}ol.lst-kix_list_3-8{list-style-type:none}.lst-kix_list_21-0>li:before{content:"" counter(lst-ctn-kix_list_21-0,decimal) ". "}.lst-kix_list_13-1>li{counter-increment:lst-ctn-kix_list_13-1}.lst-kix_list_21-1>li:before{content:"" counter(lst-ctn-kix_list_21-1,decimal) ". "}ol.lst-kix_list_15-8.start{counter-reset:lst-ctn-kix_list_15-8 0}.lst-kix_list_10-2>li{counter-increment:lst-ctn-kix_list_10-2}.lst-kix_list_21-5>li:before{content:"" counter(lst-ctn-kix_list_21-5,decimal) ". "}.lst-kix_list_21-4>li:before{content:"" counter(lst-ctn-kix_list_21-4,decimal) ". "}.lst-kix_k5epc2kusrs0-4>li:before{content:"\0025cb  "}ol.lst-kix_list_7-2.start{counter-reset:lst-ctn-kix_list_7-2 0}ol.lst-kix_list_19-5.start{counter-reset:lst-ctn-kix_list_19-5 0}ol.lst-kix_list_12-5{list-style-type:none}ol.lst-kix_list_12-6{list-style-type:none}ol.lst-kix_list_12-7{list-style-type:none}ol.lst-kix_list_12-8{list-style-type:none}ol.lst-kix_list_12-1{list-style-type:none}ol.lst-kix_list_12-2{list-style-type:none}ol.lst-kix_list_12-3{list-style-type:none}ol.lst-kix_list_12-4{list-style-type:none}ol.lst-kix_list_12-0{list-style-type:none}.lst-kix_wg014qgjj4p4-3>li{counter-increment:lst-ctn-kix_wg014qgjj4p4-3}.lst-kix_list_21-0>li{counter-increment:lst-ctn-kix_list_21-0}ol.lst-kix_list_10-8.start{counter-reset:lst-ctn-kix_list_10-8 0}.lst-kix_81qdu2dxiajy-8>li{counter-increment:lst-ctn-kix_81qdu2dxiajy-8}ol.lst-kix_list_7-1.start{counter-reset:lst-ctn-kix_list_7-1 0}.lst-kix_list_16-7>li{counter-increment:lst-ctn-kix_list_16-7}ol.lst-kix_list_21-4.start{counter-reset:lst-ctn-kix_list_21-4 0}ol.lst-kix_list_20-6.start{counter-reset:lst-ctn-kix_list_20-6 0}ol.lst-kix_638crpolklom-0.start{counter-reset:lst-ctn-kix_638crpolklom-0 0}ol.lst-kix_81qdu2dxiajy-7{list-style-type:none}ol.lst-kix_81qdu2dxiajy-8{list-style-type:none}.lst-kix_list_13-8>li{counter-increment:lst-ctn-kix_list_13-8}ol.lst-kix_81qdu2dxiajy-3{list-style-type:none}ol.lst-kix_81qdu2dxiajy-4{list-style-type:none}.lst-kix_list_2-2>li{counter-increment:lst-ctn-kix_list_2-2}ol.lst-kix_81qdu2dxiajy-5{list-style-type:none}ol.lst-kix_list_4-7.start{counter-reset:lst-ctn-kix_list_4-7 0}ol.lst-kix_81qdu2dxiajy-6{list-style-type:none}.lst-kix_list_16-5>li{counter-increment:lst-ctn-kix_list_16-5}ol.lst-kix_list_5-0{list-style-type:none}.lst-kix_list_3-7>li{counter-increment:lst-ctn-kix_list_3-7}ol.lst-kix_list_5-1{list-style-type:none}ol.lst-kix_list_5-2{list-style-type:none}.lst-kix_list_21-2>li{counter-increment:lst-ctn-kix_list_21-2}.lst-kix_list_20-2>li{counter-increment:lst-ctn-kix_list_20-2}.lst-kix_list_6-6>li{counter-increment:lst-ctn-kix_list_6-6}ol.lst-kix_list_15-7.start{counter-reset:lst-ctn-kix_list_15-7 0}.lst-kix_list_13-6>li{counter-increment:lst-ctn-kix_list_13-6}ol.lst-kix_list_14-6.start{counter-reset:lst-ctn-kix_list_14-6 0}.lst-kix_638crpolklom-5>li{counter-increment:lst-ctn-kix_638crpolklom-5}ol.lst-kix_list_5-7{list-style-type:none}ol.lst-kix_list_5-8{list-style-type:none}ol.lst-kix_list_5-3{list-style-type:none}.lst-kix_list_8-7>li{counter-increment:lst-ctn-kix_list_8-7}.lst-kix_list_19-6>li{counter-increment:lst-ctn-kix_list_19-6}ol.lst-kix_list_5-4{list-style-type:none}ol.lst-kix_list_5-5{list-style-type:none}ol.lst-kix_list_5-6{list-style-type:none}.lst-kix_list_20-4>li{counter-increment:lst-ctn-kix_list_20-4}.lst-kix_list_9-5>li{counter-increment:lst-ctn-kix_list_9-5}.lst-kix_list_5-8>li{counter-increment:lst-ctn-kix_list_5-8}ol.lst-kix_list_19-4.start{counter-reset:lst-ctn-kix_list_19-4 0}ol.lst-kix_list_2-2.start{counter-reset:lst-ctn-kix_list_2-2 0}ol.lst-kix_list_20-1.start{counter-reset:lst-ctn-kix_list_20-1 0}.lst-kix_list_19-4>li{counter-increment:lst-ctn-kix_list_19-4}ol.lst-kix_list_14-7{list-style-type:none}ol.lst-kix_list_14-8{list-style-type:none}ol.lst-kix_list_14-3{list-style-type:none}ol.lst-kix_list_21-8.start{counter-reset:lst-ctn-kix_list_21-8 0}ol.lst-kix_list_14-4{list-style-type:none}ol.lst-kix_list_14-5{list-style-type:none}ol.lst-kix_list_14-6{list-style-type:none}.lst-kix_list_15-2>li{counter-increment:lst-ctn-kix_list_15-2}ol.lst-kix_list_14-0{list-style-type:none}ol.lst-kix_list_14-1{list-style-type:none}ol.lst-kix_list_14-2{list-style-type:none}.lst-kix_list_20-5>li:before{content:"" counter(lst-ctn-kix_list_20-5,decimal) ". "}.lst-kix_list_20-1>li:before{content:"" counter(lst-ctn-kix_list_20-1,decimal) ". "}.lst-kix_list_12-3>li{counter-increment:lst-ctn-kix_list_12-3}.lst-kix_list_17-3>li{counter-increment:lst-ctn-kix_list_17-3}ol.lst-kix_list_8-4.start{counter-reset:lst-ctn-kix_list_8-4 0}ol.lst-kix_list_3-5.start{counter-reset:lst-ctn-kix_list_3-5 0}.lst-kix_list_21-7>li{counter-increment:lst-ctn-kix_list_21-7}ol.lst-kix_list_13-0.start{counter-reset:lst-ctn-kix_list_13-0 0}.lst-kix_list_14-4>li{counter-increment:lst-ctn-kix_list_14-4}.lst-kix_list_10-7>li{counter-increment:lst-ctn-kix_list_10-7}.lst-kix_list_18-1>li{counter-increment:lst-ctn-kix_list_18-1}ol.lst-kix_list_8-3.start{counter-reset:lst-ctn-kix_list_8-3 0}.lst-kix_list_11-5>li{counter-increment:lst-ctn-kix_list_11-5}ol.lst-kix_list_14-5.start{counter-reset:lst-ctn-kix_list_14-5 0}.lst-kix_81qdu2dxiajy-3>li{counter-increment:lst-ctn-kix_81qdu2dxiajy-3}ol.lst-kix_list_20-3.start{counter-reset:lst-ctn-kix_list_20-3 0}.lst-kix_list_4-1>li{counter-increment:lst-ctn-kix_list_4-1}.lst-kix_list_19-1>li:before{content:"" counter(lst-ctn-kix_list_19-1,decimal) ". "}.lst-kix_list_19-4>li:before{content:"" counter(lst-ctn-kix_list_19-4,decimal) ". "}.lst-kix_list_19-3>li:before{content:"" counter(lst-ctn-kix_list_19-3,decimal) ". "}.lst-kix_list_15-0>li{counter-increment:lst-ctn-kix_list_15-0}ol.lst-kix_list_6-6.start{counter-reset:lst-ctn-kix_list_6-6 0}.lst-kix_list_11-0>li{counter-increment:lst-ctn-kix_list_11-0}ol.lst-kix_81qdu2dxiajy-6.start{counter-reset:lst-ctn-kix_81qdu2dxiajy-6 0}ol.lst-kix_list_1-5.start{counter-reset:lst-ctn-kix_list_1-5 0}ol.lst-kix_list_9-6.start{counter-reset:lst-ctn-kix_list_9-6 0}ol.lst-kix_list_16-3.start{counter-reset:lst-ctn-kix_list_16-3 0}ol.lst-kix_list_4-5.start{counter-reset:lst-ctn-kix_list_4-5 0}.lst-kix_81qdu2dxiajy-7>li{counter-increment:lst-ctn-kix_81qdu2dxiajy-7}ol.lst-kix_list_11-2.start{counter-reset:lst-ctn-kix_list_11-2 0}.lst-kix_list_5-2>li{counter-increment:lst-ctn-kix_list_5-2}.lst-kix_list_19-6>li:before{content:"" counter(lst-ctn-kix_list_19-6,decimal) ". "}ol.lst-kix_list_8-7.start{counter-reset:lst-ctn-kix_list_8-7 0}.lst-kix_list_17-2>li{counter-increment:lst-ctn-kix_list_17-2}.lst-kix_list_20-5>li{counter-increment:lst-ctn-kix_list_20-5}.lst-kix_list_18-3>li{counter-increment:lst-ctn-kix_list_18-3}.lst-kix_list_21-6>li{counter-increment:lst-ctn-kix_list_21-6}.lst-kix_list_10-3>li{counter-increment:lst-ctn-kix_list_10-3}ol.lst-kix_list_1-0.start{counter-reset:lst-ctn-kix_list_1-0 0}.lst-kix_list_18-0>li:before{content:"" counter(lst-ctn-kix_list_18-0,decimal) ". "}ol.lst-kix_list_13-3.start{counter-reset:lst-ctn-kix_list_13-3 0}.lst-kix_list_3-0>li{counter-increment:lst-ctn-kix_list_3-0}.lst-kix_list_18-2>li:before{content:"" counter(lst-ctn-kix_list_18-2,decimal) ". "}ol.lst-kix_list_4-0.start{counter-reset:lst-ctn-kix_list_4-0 0}ol.lst-kix_list_11-7.start{counter-reset:lst-ctn-kix_list_11-7 0}ol.lst-kix_list_14-2.start{counter-reset:lst-ctn-kix_list_14-2 0}.lst-kix_list_16-1>li{counter-increment:lst-ctn-kix_list_16-1}.lst-kix_list_17-5>li{counter-increment:lst-ctn-kix_list_17-5}ol.lst-kix_list_9-4.start{counter-reset:lst-ctn-kix_list_9-4 0}.lst-kix_list_21-3>li{counter-increment:lst-ctn-kix_list_21-3}.lst-kix_list_18-8>li:before{content:"" counter(lst-ctn-kix_list_18-8,decimal) ". "}.lst-kix_list_17-6>li{counter-increment:lst-ctn-kix_list_17-6}.lst-kix_638crpolklom-8>li:before{content:"" counter(lst-ctn-kix_638crpolklom-8,lower-roman) ". "}ol.lst-kix_list_4-3.start{counter-reset:lst-ctn-kix_list_4-3 0}.lst-kix_638crpolklom-2>li:before{content:"" counter(lst-ctn-kix_638crpolklom-2,lower-roman) ". "}.lst-kix_list_10-7>li:before{content:"" counter(lst-ctn-kix_list_10-7,decimal) ". "}.lst-kix_list_7-8>li{counter-increment:lst-ctn-kix_list_7-8}.lst-kix_list_20-1>li{counter-increment:lst-ctn-kix_list_20-1}.lst-kix_list_10-5>li:before{content:"" counter(lst-ctn-kix_list_10-5,decimal) ". "}ol.lst-kix_list_13-5.start{counter-reset:lst-ctn-kix_list_13-5 0}ol.lst-kix_list_18-6.start{counter-reset:lst-ctn-kix_list_18-6 0}ol.lst-kix_list_20-8{list-style-type:none}ol.lst-kix_list_13-8.start{counter-reset:lst-ctn-kix_list_13-8 0}ol.lst-kix_list_20-5{list-style-type:none}ol.lst-kix_list_20-4{list-style-type:none}ol.lst-kix_list_20-7{list-style-type:none}.lst-kix_list_11-7>li{counter-increment:lst-ctn-kix_list_11-7}ol.lst-kix_list_20-6{list-style-type:none}.lst-kix_list_9-2>li:before{content:"" counter(lst-ctn-kix_list_9-2,decimal) ". "}ol.lst-kix_list_20-1{list-style-type:none}ol.lst-kix_list_20-0{list-style-type:none}ol.lst-kix_list_20-3{list-style-type:none}ol.lst-kix_list_20-2{list-style-type:none}ol.lst-kix_list_14-0.start{counter-reset:lst-ctn-kix_list_14-0 0}.lst-kix_list_12-5>li{counter-increment:lst-ctn-kix_list_12-5}.lst-kix_list_5-5>li{counter-increment:lst-ctn-kix_list_5-5}.lst-kix_638crpolklom-0>li:before{content:"" counter(lst-ctn-kix_638crpolklom-0,upper-latin) ". "}.lst-kix_list_9-0>li:before{content:"" counter(lst-ctn-kix_list_9-0,decimal) ". "}ol.lst-kix_81qdu2dxiajy-1.start{counter-reset:lst-ctn-kix_81qdu2dxiajy-1 0}.lst-kix_list_16-8>li{counter-increment:lst-ctn-kix_list_16-8}.lst-kix_list_11-3>li:before{content:"" counter(lst-ctn-kix_list_11-3,decimal) ". "}.lst-kix_list_6-3>li{counter-increment:lst-ctn-kix_list_6-3}ol.lst-kix_list_18-4.start{counter-reset:lst-ctn-kix_list_18-4 0}ol.lst-kix_list_1-3.start{counter-reset:lst-ctn-kix_list_1-3 0}ol.lst-kix_list_1-2.start{counter-reset:lst-ctn-kix_list_1-2 0}.lst-kix_list_20-4>li:before{content:"" counter(lst-ctn-kix_list_20-4,decimal) ". "}ol.lst-kix_list_6-1.start{counter-reset:lst-ctn-kix_list_6-1 0}ol.lst-kix_wg014qgjj4p4-3{list-style-type:none}.lst-kix_list_20-2>li:before{content:"" counter(lst-ctn-kix_list_20-2,decimal) ". "}ol.lst-kix_wg014qgjj4p4-2{list-style-type:none}ol.lst-kix_wg014qgjj4p4-1{list-style-type:none}ol.lst-kix_wg014qgjj4p4-0{list-style-type:none}.lst-kix_list_9-8>li:before{content:"" counter(lst-ctn-kix_list_9-8,decimal) ". "}ol.lst-kix_wg014qgjj4p4-7{list-style-type:none}ol.lst-kix_wg014qgjj4p4-6{list-style-type:none}ol.lst-kix_wg014qgjj4p4-5{list-style-type:none}ol.lst-kix_wg014qgjj4p4-4{list-style-type:none}ol.lst-kix_list_16-8.start{counter-reset:lst-ctn-kix_list_16-8 0}ol.lst-kix_wg014qgjj4p4-8{list-style-type:none}.lst-kix_list_4-8>li{counter-increment:lst-ctn-kix_list_4-8}.lst-kix_list_1-7>li:before{content:"" counter(lst-ctn-kix_list_1-7,lower-latin) ". "}.lst-kix_list_1-5>li:before{content:"" counter(lst-ctn-kix_list_1-5,lower-roman) ". "}ol.lst-kix_list_9-1.start{counter-reset:lst-ctn-kix_list_9-1 0}.lst-kix_list_5-6>li{counter-increment:lst-ctn-kix_list_5-6}.lst-kix_list_2-1>li:before{content:"" counter(lst-ctn-kix_list_2-1,lower-latin) ". "}.lst-kix_list_19-8>li{counter-increment:lst-ctn-kix_list_19-8}.lst-kix_list_2-3>li:before{content:"" counter(lst-ctn-kix_list_2-3,decimal) ". "}.lst-kix_81qdu2dxiajy-0>li{counter-increment:lst-ctn-kix_81qdu2dxiajy-0}.lst-kix_list_11-8>li{counter-increment:lst-ctn-kix_list_11-8}.lst-kix_k5epc2kusrs0-2>li:before{content:"\0025a0  "}.lst-kix_list_20-8>li{counter-increment:lst-ctn-kix_list_20-8}ol.lst-kix_81qdu2dxiajy-3.start{counter-reset:lst-ctn-kix_81qdu2dxiajy-3 0}.lst-kix_list_9-1>li{counter-increment:lst-ctn-kix_list_9-1}.lst-kix_list_3-2>li:before{content:"" counter(lst-ctn-kix_list_3-2,decimal) ". "}.lst-kix_list_8-1>li:before{content:"" counter(lst-ctn-kix_list_8-1,decimal) ". "}ol.lst-kix_list_1-8.start{counter-reset:lst-ctn-kix_list_1-8 0}.lst-kix_list_6-0>li{counter-increment:lst-ctn-kix_list_6-0}.lst-kix_list_3-5>li:before{content:"" counter(lst-ctn-kix_list_3-5,decimal) ". "}.lst-kix_list_18-0>li{counter-increment:lst-ctn-kix_list_18-0}ol.lst-kix_list_11-5.start{counter-reset:lst-ctn-kix_list_11-5 0}.lst-kix_list_11-1>li{counter-increment:lst-ctn-kix_list_11-1}.lst-kix_list_8-6>li:before{content:"" counter(lst-ctn-kix_list_8-6,decimal) ". "}.lst-kix_list_21-6>li:before{content:"" counter(lst-ctn-kix_list_21-6,decimal) ". "}ol.lst-kix_list_16-6.start{counter-reset:lst-ctn-kix_list_16-6 0}.lst-kix_k5epc2kusrs0-5>li:before{content:"\0025a0  "}ol.lst-kix_list_4-2.start{counter-reset:lst-ctn-kix_list_4-2 0}ol.lst-kix_list_16-0.start{counter-reset:lst-ctn-kix_list_16-0 0}.lst-kix_list_21-3>li:before{content:"" counter(lst-ctn-kix_list_21-3,decimal) ". "}ol.lst-kix_list_18-7.start{counter-reset:lst-ctn-kix_list_18-7 0}ol.lst-kix_list_11-6.start{counter-reset:lst-ctn-kix_list_11-6 0}.lst-kix_list_4-4>li{counter-increment:lst-ctn-kix_list_4-4}ol.lst-kix_list_6-4.start{counter-reset:lst-ctn-kix_list_6-4 0}.lst-kix_list_17-1>li:before{content:"" counter(lst-ctn-kix_list_17-1,decimal) ". "}.lst-kix_81qdu2dxiajy-4>li{counter-increment:lst-ctn-kix_81qdu2dxiajy-4}ol.lst-kix_list_4-1.start{counter-reset:lst-ctn-kix_list_4-1 0}.lst-kix_list_16-2>li:before{content:"" counter(lst-ctn-kix_list_16-2,decimal) ". "}ol.lst-kix_81qdu2dxiajy-4.start{counter-reset:lst-ctn-kix_81qdu2dxiajy-4 0}.lst-kix_list_16-5>li:before{content:"" counter(lst-ctn-kix_list_16-5,decimal) ". "}.lst-kix_81qdu2dxiajy-4>li:before{content:"" counter(lst-ctn-kix_81qdu2dxiajy-4,lower-latin) ". "}.lst-kix_list_15-3>li{counter-increment:lst-ctn-kix_list_15-3}ol.lst-kix_list_11-0.start{counter-reset:lst-ctn-kix_list_11-0 0}ol.lst-kix_list_18-8.start{counter-reset:lst-ctn-kix_list_18-8 0}.lst-kix_list_3-3>li{counter-increment:lst-ctn-kix_list_3-3}.lst-kix_list_16-4>li{counter-increment:lst-ctn-kix_list_16-4}ol.lst-kix_list_6-3.start{counter-reset:lst-ctn-kix_list_6-3 0}.lst-kix_638crpolklom-6>li{counter-increment:lst-ctn-kix_638crpolklom-6}ol.lst-kix_list_16-5.start{counter-reset:lst-ctn-kix_list_16-5 0}.lst-kix_list_17-6>li:before{content:"" counter(lst-ctn-kix_list_17-6,decimal) ". "}.lst-kix_list_2-6>li:before{content:"" counter(lst-ctn-kix_list_2-6,decimal) ". "}ol.lst-kix_list_16-2.start{counter-reset:lst-ctn-kix_list_16-2 0}.lst-kix_list_14-5>li{counter-increment:lst-ctn-kix_list_14-5}.lst-kix_wg014qgjj4p4-6>li:before{content:"" counter(lst-ctn-kix_wg014qgjj4p4-6,decimal) ". "}.lst-kix_list_7-5>li:before{content:"" counter(lst-ctn-kix_list_7-5,decimal) ". "}.lst-kix_list_19-5>li{counter-increment:lst-ctn-kix_list_19-5}ol.lst-kix_list_11-1.start{counter-reset:lst-ctn-kix_list_11-1 0}.lst-kix_list_18-5>li:before{content:"" counter(lst-ctn-kix_list_18-5,decimal) ". "}.lst-kix_list_13-6>li:before{content:"" counter(lst-ctn-kix_list_13-6,decimal) ". "}.lst-kix_list_6-7>li{counter-increment:lst-ctn-kix_list_6-7}.lst-kix_list_10-6>li{counter-increment:lst-ctn-kix_list_10-6}.lst-kix_list_1-7>li{counter-increment:lst-ctn-kix_list_1-7}.lst-kix_list_7-5>li{counter-increment:lst-ctn-kix_list_7-5}.lst-kix_list_15-6>li:before{content:"" counter(lst-ctn-kix_list_15-6,decimal) ". "}.lst-kix_list_11-4>li{counter-increment:lst-ctn-kix_list_11-4}.lst-kix_638crpolklom-5>li:before{content:"" counter(lst-ctn-kix_638crpolklom-5,lower-roman) ". "}ol.lst-kix_list_6-8.start{counter-reset:lst-ctn-kix_list_6-8 0}.lst-kix_list_10-2>li:before{content:"" counter(lst-ctn-kix_list_10-2,decimal) ". "}.lst-kix_81qdu2dxiajy-1>li:before{content:"" counter(lst-ctn-kix_81qdu2dxiajy-1,lower-latin) ". "}.lst-kix_list_13-7>li{counter-increment:lst-ctn-kix_list_13-7}ol.lst-kix_list_1-7.start{counter-reset:lst-ctn-kix_list_1-7 0}.lst-kix_list_20-7>li:before{content:"" counter(lst-ctn-kix_list_20-7,decimal) ". "}ol.lst-kix_list_6-5.start{counter-reset:lst-ctn-kix_list_6-5 0}.lst-kix_list_4-6>li:before{content:"" counter(lst-ctn-kix_list_4-6,decimal) ". "}ol.lst-kix_81qdu2dxiajy-5.start{counter-reset:lst-ctn-kix_81qdu2dxiajy-5 0}ol.lst-kix_81qdu2dxiajy-8.start{counter-reset:lst-ctn-kix_81qdu2dxiajy-8 0}ol.lst-kix_list_6-7.start{counter-reset:lst-ctn-kix_list_6-7 0}.lst-kix_list_12-2>li{counter-increment:lst-ctn-kix_list_12-2}.lst-kix_list_9-5>li:before{content:"" counter(lst-ctn-kix_list_9-5,decimal) ". "}.lst-kix_list_12-2>li:before{content:"" counter(lst-ctn-kix_list_12-2,decimal) ". "}.lst-kix_list_11-6>li:before{content:"" counter(lst-ctn-kix_list_11-6,decimal) ". "}ol.lst-kix_list_11-3.start{counter-reset:lst-ctn-kix_list_11-3 0}.lst-kix_list_1-2>li:before{content:"" counter(lst-ctn-kix_list_1-2,lower-roman) ". "}.lst-kix_wg014qgjj4p4-7>li{counter-increment:lst-ctn-kix_wg014qgjj4p4-7}.lst-kix_list_1-0>li{counter-increment:lst-ctn-kix_list_1-0}ol.lst-kix_list_16-1.start{counter-reset:lst-ctn-kix_list_16-1 0}ol.lst-kix_81qdu2dxiajy-7.start{counter-reset:lst-ctn-kix_81qdu2dxiajy-7 0}.lst-kix_list_18-7>li{counter-increment:lst-ctn-kix_list_18-7}ol.lst-kix_list_11-4.start{counter-reset:lst-ctn-kix_list_11-4 0}.lst-kix_list_14-1>li:before{content:"" counter(lst-ctn-kix_list_14-1,decimal) ". "}.lst-kix_list_14-3>li:before{content:"" counter(lst-ctn-kix_list_14-3,decimal) ". "}ol.lst-kix_list_15-6{list-style-type:none}ol.lst-kix_list_15-7{list-style-type:none}ol.lst-kix_list_15-8{list-style-type:none}.lst-kix_list_14-0>li:before{content:"" counter(lst-ctn-kix_list_14-0,decimal) ". "}.lst-kix_list_14-4>li:before{content:"" counter(lst-ctn-kix_list_14-4,decimal) ". "}ol.lst-kix_list_15-2{list-style-type:none}ol.lst-kix_list_15-3{list-style-type:none}ol.lst-kix_list_15-4{list-style-type:none}ol.lst-kix_list_18-5.start{counter-reset:lst-ctn-kix_list_18-5 0}.lst-kix_list_6-1>li{counter-increment:lst-ctn-kix_list_6-1}.lst-kix_list_14-5>li:before{content:"" counter(lst-ctn-kix_list_14-5,decimal) ". "}.lst-kix_list_14-7>li:before{content:"" counter(lst-ctn-kix_list_14-7,decimal) ". "}ol.lst-kix_list_15-5{list-style-type:none}ol.lst-kix_list_15-0{list-style-type:none}.lst-kix_list_14-6>li:before{content:"" counter(lst-ctn-kix_list_14-6,decimal) ". "}ol.lst-kix_list_15-1{list-style-type:none}ol.lst-kix_list_7-4.start{counter-reset:lst-ctn-kix_list_7-4 0}.lst-kix_list_17-0>li{counter-increment:lst-ctn-kix_list_17-0}.lst-kix_list_9-0>li{counter-increment:lst-ctn-kix_list_9-0}ol.lst-kix_list_11-8.start{counter-reset:lst-ctn-kix_list_11-8 0}.lst-kix_wg014qgjj4p4-0>li{counter-increment:lst-ctn-kix_wg014qgjj4p4-0}.lst-kix_list_14-2>li:before{content:"" counter(lst-ctn-kix_list_14-2,decimal) ". "}.lst-kix_list_20-7>li{counter-increment:lst-ctn-kix_list_20-7}.lst-kix_81qdu2dxiajy-5>li{counter-increment:lst-ctn-kix_81qdu2dxiajy-5}ol.lst-kix_list_12-0.start{counter-reset:lst-ctn-kix_list_12-0 0}ol.lst-kix_list_21-6.start{counter-reset:lst-ctn-kix_list_21-6 0}ol.lst-kix_list_3-7.start{counter-reset:lst-ctn-kix_list_3-7 0}.lst-kix_list_14-8>li:before{content:"" counter(lst-ctn-kix_list_14-8,decimal) ". "}.lst-kix_list_3-2>li{counter-increment:lst-ctn-kix_list_3-2}ol.lst-kix_638crpolklom-8.start{counter-reset:lst-ctn-kix_638crpolklom-8 0}ol.lst-kix_list_15-5.start{counter-reset:lst-ctn-kix_list_15-5 0}.lst-kix_list_5-0>li:before{content:"" counter(lst-ctn-kix_list_5-0,decimal) ". "}ol.lst-kix_list_6-0{list-style-type:none}ol.lst-kix_list_6-1{list-style-type:none}.lst-kix_list_14-8>li{counter-increment:lst-ctn-kix_list_14-8}.lst-kix_list_5-4>li{counter-increment:lst-ctn-kix_list_5-4}.lst-kix_list_5-3>li:before{content:"" counter(lst-ctn-kix_list_5-3,decimal) ". "}.lst-kix_list_5-2>li:before{content:"" counter(lst-ctn-kix_list_5-2,decimal) ". "}.lst-kix_list_8-3>li{counter-increment:lst-ctn-kix_list_8-3}.lst-kix_list_5-1>li:before{content:"" counter(lst-ctn-kix_list_5-1,decimal) ". "}ol.lst-kix_list_18-0.start{counter-reset:lst-ctn-kix_list_18-0 0}.lst-kix_list_5-7>li:before{content:"" counter(lst-ctn-kix_list_5-7,decimal) ". "}.lst-kix_list_5-6>li:before{content:"" counter(lst-ctn-kix_list_5-6,decimal) ". "}.lst-kix_list_5-8>li:before{content:"" counter(lst-ctn-kix_list_5-8,decimal) ". "}ol.lst-kix_list_6-6{list-style-type:none}ol.lst-kix_list_6-7{list-style-type:none}.lst-kix_list_5-4>li:before{content:"" counter(lst-ctn-kix_list_5-4,decimal) ". "}ol.lst-kix_list_6-8{list-style-type:none}.lst-kix_list_5-5>li:before{content:"" counter(lst-ctn-kix_list_5-5,decimal) ". "}ol.lst-kix_list_6-2{list-style-type:none}ol.lst-kix_list_6-3{list-style-type:none}ol.lst-kix_list_6-4{list-style-type:none}ol.lst-kix_list_6-5{list-style-type:none}ol.lst-kix_list_12-5.start{counter-reset:lst-ctn-kix_list_12-5 0}.lst-kix_list_6-1>li:before{content:"" counter(lst-ctn-kix_list_6-1,decimal) ". "}.lst-kix_list_6-3>li:before{content:"" counter(lst-ctn-kix_list_6-3,decimal) ". "}.lst-kix_list_6-8>li{counter-increment:lst-ctn-kix_list_6-8}.lst-kix_list_6-0>li:before{content:"" counter(lst-ctn-kix_list_6-0,decimal) ". "}.lst-kix_list_6-4>li:before{content:"" counter(lst-ctn-kix_list_6-4,decimal) ". "}ol.lst-kix_list_14-8.start{counter-reset:lst-ctn-kix_list_14-8 0}ol.lst-kix_wg014qgjj4p4-2.start{counter-reset:lst-ctn-kix_wg014qgjj4p4-2 0}.lst-kix_list_6-2>li:before{content:"" counter(lst-ctn-kix_list_6-2,decimal) ". "}ol.lst-kix_list_15-0.start{counter-reset:lst-ctn-kix_list_15-0 0}.lst-kix_list_2-5>li{counter-increment:lst-ctn-kix_list_2-5}ol.lst-kix_list_3-2.start{counter-reset:lst-ctn-kix_list_3-2 0}.lst-kix_list_6-8>li:before{content:"" counter(lst-ctn-kix_list_6-8,decimal) ". "}.lst-kix_list_6-5>li:before{content:"" counter(lst-ctn-kix_list_6-5,decimal) ". "}.lst-kix_list_6-7>li:before{content:"" counter(lst-ctn-kix_list_6-7,decimal) ". "}.lst-kix_list_6-6>li:before{content:"" counter(lst-ctn-kix_list_6-6,decimal) ". "}ol.lst-kix_list_17-8{list-style-type:none}ol.lst-kix_list_10-6.start{counter-reset:lst-ctn-kix_list_10-6 0}.lst-kix_list_7-4>li:before{content:"" counter(lst-ctn-kix_list_7-4,decimal) ". "}.lst-kix_list_7-6>li:before{content:"" counter(lst-ctn-kix_list_7-6,decimal) ". "}ol.lst-kix_list_17-4{list-style-type:none}.lst-kix_list_18-5>li{counter-increment:lst-ctn-kix_list_18-5}ol.lst-kix_list_19-7.start{counter-reset:lst-ctn-kix_list_19-7 0}.lst-kix_wg014qgjj4p4-7>li:before{content:"" counter(lst-ctn-kix_wg014qgjj4p4-7,lower-latin) ". "}ol.lst-kix_list_17-5{list-style-type:none}ol.lst-kix_list_6-2.start{counter-reset:lst-ctn-kix_list_6-2 0}.lst-kix_list_15-5>li{counter-increment:lst-ctn-kix_list_15-5}ol.lst-kix_list_17-6{list-style-type:none}ol.lst-kix_list_17-7{list-style-type:none}ol.lst-kix_list_17-0{list-style-type:none}ol.lst-kix_list_17-1{list-style-type:none}ol.lst-kix_list_17-2{list-style-type:none}.lst-kix_list_7-2>li:before{content:"" counter(lst-ctn-kix_list_7-2,decimal) ". "}ol.lst-kix_list_17-3{list-style-type:none}.lst-kix_list_7-6>li{counter-increment:lst-ctn-kix_list_7-6}.lst-kix_wg014qgjj4p4-1>li:before{content:"" counter(lst-ctn-kix_wg014qgjj4p4-1,lower-latin) ". "}.lst-kix_list_12-6>li{counter-increment:lst-ctn-kix_list_12-6}.lst-kix_wg014qgjj4p4-3>li:before{content:"" counter(lst-ctn-kix_wg014qgjj4p4-3,decimal) ". "}.lst-kix_list_13-7>li:before{content:"" counter(lst-ctn-kix_list_13-7,decimal) ". "}.lst-kix_wg014qgjj4p4-5>li:before{content:"" counter(lst-ctn-kix_wg014qgjj4p4-5,lower-roman) ". "}.lst-kix_list_7-8>li:before{content:"" counter(lst-ctn-kix_list_7-8,decimal) ". "}.lst-kix_list_15-6>li{counter-increment:lst-ctn-kix_list_15-6}.lst-kix_list_4-7>li{counter-increment:lst-ctn-kix_list_4-7}ol.lst-kix_list_2-5.start{counter-reset:lst-ctn-kix_list_2-5 0}.lst-kix_list_15-5>li:before{content:"" counter(lst-ctn-kix_list_15-5,decimal) ". "}.lst-kix_list_9-8>li{counter-increment:lst-ctn-kix_list_9-8}.lst-kix_list_13-4>li{counter-increment:lst-ctn-kix_list_13-4}.lst-kix_list_4-1>li:before{content:"" counter(lst-ctn-kix_list_4-1,decimal) ". "}.lst-kix_list_15-7>li:before{content:"" counter(lst-ctn-kix_list_15-7,decimal) ". "}.lst-kix_list_17-7>li{counter-increment:lst-ctn-kix_list_17-7}ol.lst-kix_wg014qgjj4p4-7.start{counter-reset:lst-ctn-kix_wg014qgjj4p4-7 0}.lst-kix_list_4-3>li:before{content:"" counter(lst-ctn-kix_list_4-3,decimal) ". "}.lst-kix_list_4-5>li:before{content:"" counter(lst-ctn-kix_list_4-5,decimal) ". "}.lst-kix_list_1-8>li{counter-increment:lst-ctn-kix_list_1-8}.lst-kix_list_10-5>li{counter-increment:lst-ctn-kix_list_10-5}.lst-kix_list_15-1>li:before{content:"" counter(lst-ctn-kix_list_15-1,decimal) ". "}ol.lst-kix_list_1-4.start{counter-reset:lst-ctn-kix_list_1-4 0}.lst-kix_list_15-3>li:before{content:"" counter(lst-ctn-kix_list_15-3,decimal) ". "}.lst-kix_638crpolklom-1>li{counter-increment:lst-ctn-kix_638crpolklom-1}ol.lst-kix_list_4-4.start{counter-reset:lst-ctn-kix_list_4-4 0}.lst-kix_list_16-2>li{counter-increment:lst-ctn-kix_list_16-2}ol.lst-kix_list_9-2.start{counter-reset:lst-ctn-kix_list_9-2 0}.lst-kix_list_20-0>li{counter-increment:lst-ctn-kix_list_20-0}ol.lst-kix_list_16-7.start{counter-reset:lst-ctn-kix_list_16-7 0}.lst-kix_list_11-2>li{counter-increment:lst-ctn-kix_list_11-2}.lst-kix_list_19-2>li{counter-increment:lst-ctn-kix_list_19-2}ol.lst-kix_list_8-8{list-style-type:none}.lst-kix_list_12-3>li:before{content:"" counter(lst-ctn-kix_list_12-3,decimal) ". "}ol.lst-kix_list_8-4{list-style-type:none}.lst-kix_list_12-1>li:before{content:"" counter(lst-ctn-kix_list_12-1,decimal) ". "}.lst-kix_638crpolklom-2>li{counter-increment:lst-ctn-kix_638crpolklom-2}ol.lst-kix_list_8-5{list-style-type:none}ol.lst-kix_list_8-6{list-style-type:none}ol.lst-kix_list_8-7{list-style-type:none}ol.lst-kix_list_8-0{list-style-type:none}.lst-kix_list_16-3>li{counter-increment:lst-ctn-kix_list_16-3}ol.lst-kix_list_8-1{list-style-type:none}ol.lst-kix_list_8-2{list-style-type:none}.lst-kix_list_13-3>li{counter-increment:lst-ctn-kix_list_13-3}ol.lst-kix_list_13-6.start{counter-reset:lst-ctn-kix_list_13-6 0}ol.lst-kix_list_8-3{list-style-type:none}.lst-kix_list_10-4>li{counter-increment:lst-ctn-kix_list_10-4}.lst-kix_list_14-1>li{counter-increment:lst-ctn-kix_list_14-1}.lst-kix_list_21-4>li{counter-increment:lst-ctn-kix_list_21-4}.lst-kix_list_13-3>li:before{content:"" counter(lst-ctn-kix_list_13-3,decimal) ". "}.lst-kix_list_13-5>li:before{content:"" counter(lst-ctn-kix_list_13-5,decimal) ". "}.lst-kix_list_12-5>li:before{content:"" counter(lst-ctn-kix_list_12-5,decimal) ". "}ol.lst-kix_list_13-7.start{counter-reset:lst-ctn-kix_list_13-7 0}.lst-kix_list_18-4>li{counter-increment:lst-ctn-kix_list_18-4}.lst-kix_list_12-7>li:before{content:"" counter(lst-ctn-kix_list_12-7,decimal) ". "}ol.lst-kix_list_21-1.start{counter-reset:lst-ctn-kix_list_21-1 0}ol.lst-kix_638crpolklom-3.start{counter-reset:lst-ctn-kix_638crpolklom-3 0}ol.lst-kix_81qdu2dxiajy-0.start{counter-reset:lst-ctn-kix_81qdu2dxiajy-0 0}.lst-kix_list_13-1>li:before{content:"" counter(lst-ctn-kix_list_13-1,decimal) ". "}ol.lst-kix_list_11-6{list-style-type:none}ol.lst-kix_list_11-7{list-style-type:none}ol.lst-kix_list_11-8{list-style-type:none}.lst-kix_list_1-1>li{counter-increment:lst-ctn-kix_list_1-1}ol.lst-kix_list_11-2{list-style-type:none}ol.lst-kix_list_11-3{list-style-type:none}ol.lst-kix_list_2-6.start{counter-reset:lst-ctn-kix_list_2-6 0}.lst-kix_list_3-0>li:before{content:"" counter(lst-ctn-kix_list_3-0,decimal) ". "}ol.lst-kix_list_11-4{list-style-type:none}ol.lst-kix_list_11-5{list-style-type:none}ol.lst-kix_list_20-5.start{counter-reset:lst-ctn-kix_list_20-5 0}ol.lst-kix_list_13-1.start{counter-reset:lst-ctn-kix_list_13-1 0}ol.lst-kix_list_11-0{list-style-type:none}ol.lst-kix_list_11-1{list-style-type:none}.lst-kix_list_4-0>li{counter-increment:lst-ctn-kix_list_4-0}.lst-kix_list_3-4>li:before{content:"" counter(lst-ctn-kix_list_3-4,decimal) ". "}.lst-kix_list_3-3>li:before{content:"" counter(lst-ctn-kix_list_3-3,decimal) ". "}.lst-kix_list_8-0>li:before{content:"" counter(lst-ctn-kix_list_8-0,decimal) ". "}.lst-kix_list_8-7>li:before{content:"" counter(lst-ctn-kix_list_8-7,decimal) ". "}.lst-kix_list_3-8>li:before{content:"" counter(lst-ctn-kix_list_3-8,decimal) ". "}ol.lst-kix_list_10-7.start{counter-reset:lst-ctn-kix_list_10-7 0}.lst-kix_list_8-3>li:before{content:"" counter(lst-ctn-kix_list_8-3,decimal) ". "}.lst-kix_list_3-7>li:before{content:"" counter(lst-ctn-kix_list_3-7,decimal) ". "}.lst-kix_list_8-4>li:before{content:"" counter(lst-ctn-kix_list_8-4,decimal) ". "}.lst-kix_list_19-1>li{counter-increment:lst-ctn-kix_list_19-1}ol.lst-kix_list_8-5.start{counter-reset:lst-ctn-kix_list_8-5 0}.lst-kix_list_17-1>li{counter-increment:lst-ctn-kix_list_17-1}.lst-kix_list_11-1>li:before{content:"" counter(lst-ctn-kix_list_11-1,decimal) ". "}.lst-kix_list_11-0>li:before{content:"" counter(lst-ctn-kix_list_11-0,decimal) ". "}ol.lst-kix_list_9-3.start{counter-reset:lst-ctn-kix_list_9-3 0}.lst-kix_list_8-8>li:before{content:"" counter(lst-ctn-kix_list_8-8,decimal) ". "}ol.lst-kix_list_2-2{list-style-type:none}.lst-kix_list_16-8>li:before{content:"" counter(lst-ctn-kix_list_16-8,decimal) ". "}ol.lst-kix_list_2-3{list-style-type:none}ol.lst-kix_list_2-4{list-style-type:none}.lst-kix_list_16-7>li:before{content:"" counter(lst-ctn-kix_list_16-7,decimal) ". "}ol.lst-kix_list_2-5{list-style-type:none}.lst-kix_list_17-8>li{counter-increment:lst-ctn-kix_list_17-8}ol.lst-kix_list_2-0{list-style-type:none}ol.lst-kix_list_2-1{list-style-type:none}.lst-kix_list_4-8>li:before{content:"" counter(lst-ctn-kix_list_4-8,decimal) ". "}.lst-kix_list_21-5>li{counter-increment:lst-ctn-kix_list_21-5}.lst-kix_list_4-7>li:before{content:"" counter(lst-ctn-kix_list_4-7,decimal) ". "}.lst-kix_list_14-2>li{counter-increment:lst-ctn-kix_list_14-2}ol.lst-kix_list_20-0.start{counter-reset:lst-ctn-kix_list_20-0 0}.lst-kix_list_17-0>li:before{content:"" counter(lst-ctn-kix_list_17-0,decimal) ". "}.lst-kix_81qdu2dxiajy-6>li:before{content:"" counter(lst-ctn-kix_81qdu2dxiajy-6,decimal) ". "}.lst-kix_list_16-0>li:before{content:"" counter(lst-ctn-kix_list_16-0,decimal) ". "}ol.lst-kix_list_4-8.start{counter-reset:lst-ctn-kix_list_4-8 0}.lst-kix_81qdu2dxiajy-3>li:before{content:"" counter(lst-ctn-kix_81qdu2dxiajy-3,decimal) ". "}.lst-kix_81qdu2dxiajy-7>li:before{content:"" counter(lst-ctn-kix_81qdu2dxiajy-7,lower-latin) ". "}.lst-kix_list_8-4>li{counter-increment:lst-ctn-kix_list_8-4}.lst-kix_list_16-4>li:before{content:"" counter(lst-ctn-kix_list_16-4,decimal) ". "}ol.lst-kix_list_3-3.start{counter-reset:lst-ctn-kix_list_3-3 0}.lst-kix_list_16-3>li:before{content:"" counter(lst-ctn-kix_list_16-3,decimal) ". "}ol.lst-kix_list_2-6{list-style-type:none}ol.lst-kix_list_2-7{list-style-type:none}ol.lst-kix_list_2-8{list-style-type:none}.lst-kix_list_11-3>li{counter-increment:lst-ctn-kix_list_11-3}ol.lst-kix_list_18-1.start{counter-reset:lst-ctn-kix_list_18-1 0}ol.lst-kix_list_8-6.start{counter-reset:lst-ctn-kix_list_8-6 0}.lst-kix_list_17-7>li:before{content:"" counter(lst-ctn-kix_list_17-7,decimal) ". "}.lst-kix_list_17-8>li:before{content:"" counter(lst-ctn-kix_list_17-8,decimal) ". "}.lst-kix_list_17-3>li:before{content:"" counter(lst-ctn-kix_list_17-3,decimal) ". "}.lst-kix_list_17-4>li:before{content:"" counter(lst-ctn-kix_list_17-4,decimal) ". "}.lst-kix_638crpolklom-3>li{counter-increment:lst-ctn-kix_638crpolklom-3}ol.lst-kix_list_8-0.start{counter-reset:lst-ctn-kix_list_8-0 0}.lst-kix_list_7-0>li:before{content:"" counter(lst-ctn-kix_list_7-0,decimal) ". "}ol.lst-kix_list_19-6.start{counter-reset:lst-ctn-kix_list_19-6 0}ul.lst-kix_k5epc2kusrs0-3{list-style-type:none}.lst-kix_wg014qgjj4p4-8>li:before{content:"" counter(lst-ctn-kix_wg014qgjj4p4-8,lower-roman) ". "}ul.lst-kix_k5epc2kusrs0-4{list-style-type:none}ol.lst-kix_list_9-7.start{counter-reset:lst-ctn-kix_list_9-7 0}ul.lst-kix_k5epc2kusrs0-5{list-style-type:none}ul.lst-kix_k5epc2kusrs0-6{list-style-type:none}ol.lst-kix_list_13-8{list-style-type:none}.lst-kix_list_2-4>li:before{content:"" counter(lst-ctn-kix_list_2-4,lower-latin) ". "}.lst-kix_list_2-8>li:before{content:"" counter(lst-ctn-kix_list_2-8,lower-roman) ". "}ul.lst-kix_k5epc2kusrs0-0{list-style-type:none}ul.lst-kix_k5epc2kusrs0-1{list-style-type:none}ul.lst-kix_k5epc2kusrs0-2{list-style-type:none}ol.lst-kix_list_13-4{list-style-type:none}ol.lst-kix_list_13-5{list-style-type:none}ol.lst-kix_list_13-6{list-style-type:none}ol.lst-kix_list_13-7{list-style-type:none}ol.lst-kix_list_13-0{list-style-type:none}ol.lst-kix_list_13-1{list-style-type:none}ol.lst-kix_list_13-2{list-style-type:none}.lst-kix_list_7-3>li:before{content:"" counter(lst-ctn-kix_list_7-3,decimal) ". "}ol.lst-kix_list_13-3{list-style-type:none}ol.lst-kix_638crpolklom-8{list-style-type:none}ol.lst-kix_638crpolklom-7{list-style-type:none}.lst-kix_list_10-0>li:before{content:"" counter(lst-ctn-kix_list_10-0,decimal) ". "}ol.lst-kix_638crpolklom-6{list-style-type:none}.lst-kix_list_9-7>li{counter-increment:lst-ctn-kix_list_9-7}ol.lst-kix_list_21-7.start{counter-reset:lst-ctn-kix_list_21-7 0}ol.lst-kix_638crpolklom-5{list-style-type:none}.lst-kix_list_13-8>li:before{content:"" counter(lst-ctn-kix_list_13-8,decimal) ". "}.lst-kix_list_18-3>li:before{content:"" counter(lst-ctn-kix_list_18-3,decimal) ". "}.lst-kix_list_18-7>li:before{content:"" counter(lst-ctn-kix_list_18-7,decimal) ". "}.lst-kix_wg014qgjj4p4-6>li{counter-increment:lst-ctn-kix_wg014qgjj4p4-6}.lst-kix_wg014qgjj4p4-4>li:before{content:"" counter(lst-ctn-kix_wg014qgjj4p4-4,lower-latin) ". "}.lst-kix_638crpolklom-7>li:before{content:"" counter(lst-ctn-kix_638crpolklom-7,lower-latin) ". "}.lst-kix_list_18-6>li{counter-increment:lst-ctn-kix_list_18-6}ul.lst-kix_k5epc2kusrs0-7{list-style-type:none}ol.lst-kix_list_3-8.start{counter-reset:lst-ctn-kix_list_3-8 0}ul.lst-kix_k5epc2kusrs0-8{list-style-type:none}.lst-kix_list_7-7>li:before{content:"" counter(lst-ctn-kix_list_7-7,decimal) ". "}ol.lst-kix_list_8-1.start{counter-reset:lst-ctn-kix_list_8-1 0}.lst-kix_638crpolklom-3>li:before{content:"" counter(lst-ctn-kix_638crpolklom-3,decimal) ". "}.lst-kix_list_15-4>li:before{content:"" counter(lst-ctn-kix_list_15-4,decimal) ". "}ol.lst-kix_list_19-1.start{counter-reset:lst-ctn-kix_list_19-1 0}.lst-kix_list_10-4>li:before{content:"" counter(lst-ctn-kix_list_10-4,decimal) ". "}.lst-kix_list_10-8>li:before{content:"" counter(lst-ctn-kix_list_10-8,decimal) ". "}ol.lst-kix_list_20-4.start{counter-reset:lst-ctn-kix_list_20-4 0}ol.lst-kix_638crpolklom-0{list-style-type:none}.lst-kix_list_4-0>li:before{content:"" counter(lst-ctn-kix_list_4-0,decimal) ". "}.lst-kix_list_15-0>li:before{content:"" counter(lst-ctn-kix_list_15-0,decimal) ". "}.lst-kix_list_15-8>li:before{content:"" counter(lst-ctn-kix_list_15-8,decimal) ". "}ol.lst-kix_638crpolklom-4{list-style-type:none}ol.lst-kix_638crpolklom-3{list-style-type:none}ol.lst-kix_list_14-3.start{counter-reset:lst-ctn-kix_list_14-3 0}ol.lst-kix_638crpolklom-2{list-style-type:none}.lst-kix_list_15-7>li{counter-increment:lst-ctn-kix_list_15-7}ol.lst-kix_638crpolklom-1{list-style-type:none}.lst-kix_list_4-4>li:before{content:"" counter(lst-ctn-kix_list_4-4,decimal) ". "}.lst-kix_wg014qgjj4p4-0>li:before{content:"" counter(lst-ctn-kix_wg014qgjj4p4-0,upper-latin) ". "}ol.lst-kix_wg014qgjj4p4-1.start{counter-reset:lst-ctn-kix_wg014qgjj4p4-1 0}.lst-kix_list_9-3>li:before{content:"" counter(lst-ctn-kix_list_9-3,decimal) ". "}ol.lst-kix_list_7-0.start{counter-reset:lst-ctn-kix_list_7-0 0}.lst-kix_list_12-8>li{counter-increment:lst-ctn-kix_list_12-8}ol.lst-kix_list_13-2.start{counter-reset:lst-ctn-kix_list_13-2 0}.lst-kix_wg014qgjj4p4-8>li{counter-increment:lst-ctn-kix_wg014qgjj4p4-8}ol.lst-kix_list_4-0{list-style-type:none}ol.lst-kix_list_4-1{list-style-type:none}ol.lst-kix_list_4-2{list-style-type:none}ol.lst-kix_list_4-3{list-style-type:none}ol.lst-kix_list_14-4.start{counter-reset:lst-ctn-kix_list_14-4 0}.lst-kix_list_9-7>li:before{content:"" counter(lst-ctn-kix_list_9-7,decimal) ". "}.lst-kix_list_2-4>li{counter-increment:lst-ctn-kix_list_2-4}ol.lst-kix_list_3-6.start{counter-reset:lst-ctn-kix_list_3-6 0}.lst-kix_list_11-4>li:before{content:"" counter(lst-ctn-kix_list_11-4,decimal) ". "}.lst-kix_list_12-4>li:before{content:"" counter(lst-ctn-kix_list_12-4,decimal) ". "}.lst-kix_list_5-3>li{counter-increment:lst-ctn-kix_list_5-3}ol.lst-kix_list_4-8{list-style-type:none}.lst-kix_list_7-4>li{counter-increment:lst-ctn-kix_list_7-4}.lst-kix_list_1-0>li:before{content:"" counter(lst-ctn-kix_list_1-0,decimal) ". "}ol.lst-kix_list_19-2.start{counter-reset:lst-ctn-kix_list_19-2 0}ol.lst-kix_list_4-4{list-style-type:none}.lst-kix_list_11-8>li:before{content:"" counter(lst-ctn-kix_list_11-8,decimal) ". "}ol.lst-kix_list_4-5{list-style-type:none}ol.lst-kix_list_2-0.start{counter-reset:lst-ctn-kix_list_2-0 0}ol.lst-kix_list_4-6{list-style-type:none}.lst-kix_list_12-0>li:before{content:"" counter(lst-ctn-kix_list_12-0,decimal) ". "}ol.lst-kix_list_4-7{list-style-type:none}.lst-kix_list_1-4>li:before{content:"" counter(lst-ctn-kix_list_1-4,lower-latin) ". "}.lst-kix_list_13-0>li:before{content:"" counter(lst-ctn-kix_list_13-0,decimal) ". "}.lst-kix_wg014qgjj4p4-1>li{counter-increment:lst-ctn-kix_wg014qgjj4p4-1}.lst-kix_list_1-6>li{counter-increment:lst-ctn-kix_list_1-6}.lst-kix_list_13-4>li:before{content:"" counter(lst-ctn-kix_list_13-4,decimal) ". "}ol.lst-kix_list_19-3.start{counter-reset:lst-ctn-kix_list_19-3 0}.lst-kix_list_2-0>li:before{content:"" counter(lst-ctn-kix_list_2-0,decimal) ". "}ol.lst-kix_list_2-1.start{counter-reset:lst-ctn-kix_list_2-1 0}.lst-kix_list_4-5>li{counter-increment:lst-ctn-kix_list_4-5}ol.lst-kix_list_9-8.start{counter-reset:lst-ctn-kix_list_9-8 0}.lst-kix_list_1-8>li:before{content:"" counter(lst-ctn-kix_list_1-8,lower-roman) ". "}.lst-kix_list_12-8>li:before{content:"" counter(lst-ctn-kix_list_12-8,decimal) ". "}.lst-kix_list_8-2>li{counter-increment:lst-ctn-kix_list_8-2}.lst-kix_list_19-0>li:before{content:"" counter(lst-ctn-kix_list_19-0,decimal) ". "}ol.lst-kix_list_17-7.start{counter-reset:lst-ctn-kix_list_17-7 0}ol.lst-kix_list_12-6.start{counter-reset:lst-ctn-kix_list_12-6 0}ol.lst-kix_wg014qgjj4p4-3.start{counter-reset:lst-ctn-kix_wg014qgjj4p4-3 0}.lst-kix_list_8-1>li{counter-increment:lst-ctn-kix_list_8-1}ol.lst-kix_list_8-2.start{counter-reset:lst-ctn-kix_list_8-2 0}.lst-kix_list_19-2>li:before{content:"" counter(lst-ctn-kix_list_19-2,decimal) ". "}ol.lst-kix_list_3-1.start{counter-reset:lst-ctn-kix_list_3-1 0}ol.lst-kix_list_21-0.start{counter-reset:lst-ctn-kix_list_21-0 0}.lst-kix_list_7-0>li{counter-increment:lst-ctn-kix_list_7-0}.lst-kix_list_19-0>li{counter-increment:lst-ctn-kix_list_19-0}.lst-kix_list_2-3>li{counter-increment:lst-ctn-kix_list_2-3}ol.lst-kix_list_19-8.start{counter-reset:lst-ctn-kix_list_19-8 0}.lst-kix_list_1-2>li{counter-increment:lst-ctn-kix_list_1-2}.lst-kix_list_19-8>li:before{content:"" counter(lst-ctn-kix_list_19-8,decimal) ". "}ol.lst-kix_list_14-7.start{counter-reset:lst-ctn-kix_list_14-7 0}ol.lst-kix_list_20-8.start{counter-reset:lst-ctn-kix_list_20-8 0}.lst-kix_wg014qgjj4p4-2>li{counter-increment:lst-ctn-kix_wg014qgjj4p4-2}.lst-kix_list_19-5>li:before{content:"" counter(lst-ctn-kix_list_19-5,decimal) ". "}.lst-kix_list_19-7>li:before{content:"" counter(lst-ctn-kix_list_19-7,decimal) ". "}.lst-kix_list_9-2>li{counter-increment:lst-ctn-kix_list_9-2}ol.lst-kix_list_17-2.start{counter-reset:lst-ctn-kix_list_17-2 0}.lst-kix_list_13-2>li{counter-increment:lst-ctn-kix_list_13-2}ol.lst-kix_list_21-5.start{counter-reset:lst-ctn-kix_list_21-5 0}.lst-kix_list_19-7>li{counter-increment:lst-ctn-kix_list_19-7}.lst-kix_list_14-3>li{counter-increment:lst-ctn-kix_list_14-3}ol.lst-kix_list_15-6.start{counter-reset:lst-ctn-kix_list_15-6 0}ol.lst-kix_wg014qgjj4p4-8.start{counter-reset:lst-ctn-kix_wg014qgjj4p4-8 0}.lst-kix_list_12-1>li{counter-increment:lst-ctn-kix_list_12-1}.lst-kix_list_18-1>li:before{content:"" counter(lst-ctn-kix_list_18-1,decimal) ". "}.lst-kix_638crpolklom-0>li{counter-increment:lst-ctn-kix_638crpolklom-0}ol.lst-kix_list_2-4.start{counter-reset:lst-ctn-kix_list_2-4 0}ol.lst-kix_list_1-3{list-style-type:none}ol.lst-kix_list_1-4{list-style-type:none}.lst-kix_list_2-7>li:before{content:"" counter(lst-ctn-kix_list_2-7,lower-latin) ". "}.lst-kix_list_2-7>li{counter-increment:lst-ctn-kix_list_2-7}ol.lst-kix_638crpolklom-4.start{counter-reset:lst-ctn-kix_638crpolklom-4 0}ol.lst-kix_list_1-5{list-style-type:none}ol.lst-kix_list_1-6{list-style-type:none}ol.lst-kix_list_1-0{list-style-type:none}.lst-kix_list_2-5>li:before{content:"" counter(lst-ctn-kix_list_2-5,lower-roman) ". "}ol.lst-kix_list_1-1{list-style-type:none}ol.lst-kix_list_1-2{list-style-type:none}ol.lst-kix_list_17-0.start{counter-reset:lst-ctn-kix_list_17-0 0}ol.lst-kix_list_10-3.start{counter-reset:lst-ctn-kix_list_10-3 0}.lst-kix_list_18-6>li:before{content:"" counter(lst-ctn-kix_list_18-6,decimal) ". "}.lst-kix_list_14-6>li{counter-increment:lst-ctn-kix_list_14-6}.lst-kix_list_10-1>li:before{content:"" counter(lst-ctn-kix_list_10-1,decimal) ". "}.lst-kix_list_18-4>li:before{content:"" counter(lst-ctn-kix_list_18-4,decimal) ". "}.lst-kix_638crpolklom-6>li:before{content:"" counter(lst-ctn-kix_638crpolklom-6,decimal) ". "}.lst-kix_list_7-7>li{counter-increment:lst-ctn-kix_list_7-7}ol.lst-kix_list_15-1.start{counter-reset:lst-ctn-kix_list_15-1 0}ol.lst-kix_list_15-4.start{counter-reset:lst-ctn-kix_list_15-4 0}ol.lst-kix_list_1-7{list-style-type:none}ol.lst-kix_list_1-8{list-style-type:none}.lst-kix_list_10-3>li:before{content:"" counter(lst-ctn-kix_list_10-3,decimal) ". "}.lst-kix_81qdu2dxiajy-2>li:before{content:"" counter(lst-ctn-kix_81qdu2dxiajy-2,lower-roman) ". "}.lst-kix_list_15-4>li{counter-increment:lst-ctn-kix_list_15-4}.lst-kix_list_2-6>li{counter-increment:lst-ctn-kix_list_2-6}ol.lst-kix_list_7-3.start{counter-reset:lst-ctn-kix_list_7-3 0}.lst-kix_638crpolklom-4>li:before{content:"" counter(lst-ctn-kix_638crpolklom-4,lower-latin) ". "}.lst-kix_81qdu2dxiajy-0>li:before{content:"" counter(lst-ctn-kix_81qdu2dxiajy-0,upper-latin) ". "}ol.lst-kix_list_5-7.start{counter-reset:lst-ctn-kix_list_5-7 0}.lst-kix_list_20-8>li:before{content:"" counter(lst-ctn-kix_list_20-8,decimal) ". "}.lst-kix_wg014qgjj4p4-5>li{counter-increment:lst-ctn-kix_wg014qgjj4p4-5}.lst-kix_list_3-4>li{counter-increment:lst-ctn-kix_list_3-4}.lst-kix_638crpolklom-7>li{counter-increment:lst-ctn-kix_638crpolklom-7}ol.lst-kix_wg014qgjj4p4-5.start{counter-reset:lst-ctn-kix_wg014qgjj4p4-5 0}.lst-kix_list_20-0>li:before{content:"" counter(lst-ctn-kix_list_20-0,decimal) ". "}ol.lst-kix_list_10-7{list-style-type:none}.lst-kix_list_9-6>li:before{content:"" counter(lst-ctn-kix_list_9-6,decimal) ". "}ol.lst-kix_list_10-8{list-style-type:none}ol.lst-kix_list_10-3{list-style-type:none}.lst-kix_list_9-4>li:before{content:"" counter(lst-ctn-kix_list_9-4,decimal) ". "}ol.lst-kix_list_10-4{list-style-type:none}ol.lst-kix_list_10-5{list-style-type:none}ol.lst-kix_list_10-6{list-style-type:none}.lst-kix_list_20-6>li:before{content:"" counter(lst-ctn-kix_list_20-6,decimal) ". "}ol.lst-kix_list_10-0{list-style-type:none}ol.lst-kix_list_10-1{list-style-type:none}ol.lst-kix_list_10-2{list-style-type:none}ol.lst-kix_list_12-1.start{counter-reset:lst-ctn-kix_list_12-1 0}ol.lst-kix_638crpolklom-2.start{counter-reset:lst-ctn-kix_638crpolklom-2 0}.lst-kix_list_11-5>li:before{content:"" counter(lst-ctn-kix_list_11-5,decimal) ". "}ol.lst-kix_list_21-2.start{counter-reset:lst-ctn-kix_list_21-2 0}.lst-kix_list_20-6>li{counter-increment:lst-ctn-kix_list_20-6}.lst-kix_list_1-1>li:before{content:"" counter(lst-ctn-kix_list_1-1,lower-latin) ". "}.lst-kix_list_11-7>li:before{content:"" counter(lst-ctn-kix_list_11-7,decimal) ". "}.lst-kix_list_8-5>li{counter-increment:lst-ctn-kix_list_8-5}.lst-kix_list_1-3>li:before{content:"" counter(lst-ctn-kix_list_1-3,decimal) ". "}.lst-kix_638crpolklom-8>li{counter-increment:lst-ctn-kix_638crpolklom-8}ol.lst-kix_list_10-5.start{counter-reset:lst-ctn-kix_list_10-5 0}ol.lst-kix_list_21-8{list-style-type:none}ol.lst-kix_wg014qgjj4p4-6.start{counter-reset:lst-ctn-kix_wg014qgjj4p4-6 0}ol.lst-kix_list_21-7{list-style-type:none}ol.lst-kix_list_2-7.start{counter-reset:lst-ctn-kix_list_2-7 0}ol.lst-kix_list_21-4{list-style-type:none}ol.lst-kix_list_21-3{list-style-type:none}ol.lst-kix_list_21-6{list-style-type:none}.lst-kix_list_14-7>li{counter-increment:lst-ctn-kix_list_14-7}ol.lst-kix_list_21-5{list-style-type:none}ol.lst-kix_list_21-0{list-style-type:none}ol.lst-kix_list_7-5.start{counter-reset:lst-ctn-kix_list_7-5 0}ol.lst-kix_list_21-2{list-style-type:none}ol.lst-kix_list_21-1{list-style-type:none}ol.lst-kix_list_19-6{list-style-type:none}ol.lst-kix_list_19-7{list-style-type:none}.lst-kix_list_3-1>li{counter-increment:lst-ctn-kix_list_3-1}.lst-kix_k5epc2kusrs0-1>li:before{content:"\0025cb  "}ol.lst-kix_list_19-8{list-style-type:none}ol.lst-kix_list_19-2{list-style-type:none}ol.lst-kix_list_19-3{list-style-type:none}.lst-kix_81qdu2dxiajy-6>li{counter-increment:lst-ctn-kix_81qdu2dxiajy-6}ol.lst-kix_list_19-4{list-style-type:none}ol.lst-kix_list_19-5{list-style-type:none}.lst-kix_k5epc2kusrs0-6>li:before{content:"\0025cf  "}ol.lst-kix_list_19-0{list-style-type:none}ol.lst-kix_list_19-1{list-style-type:none}ol.lst-kix_list_7-7.start{counter-reset:lst-ctn-kix_list_7-7 0}.lst-kix_list_3-1>li:before{content:"" counter(lst-ctn-kix_list_3-1,decimal) ". "}.lst-kix_list_14-0>li{counter-increment:lst-ctn-kix_list_14-0}ol.lst-kix_list_17-4.start{counter-reset:lst-ctn-kix_list_17-4 0}.lst-kix_list_8-2>li:before{content:"" counter(lst-ctn-kix_list_8-2,decimal) ". "}.lst-kix_list_12-0>li{counter-increment:lst-ctn-kix_list_12-0}ol.lst-kix_list_12-3.start{counter-reset:lst-ctn-kix_list_12-3 0}ol.lst-kix_638crpolklom-5.start{counter-reset:lst-ctn-kix_638crpolklom-5 0}.lst-kix_list_21-2>li:before{content:"" counter(lst-ctn-kix_list_21-2,decimal) ". "}.lst-kix_list_8-5>li:before{content:"" counter(lst-ctn-kix_list_8-5,decimal) ". "}.lst-kix_list_2-0>li{counter-increment:lst-ctn-kix_list_2-0}.lst-kix_list_15-1>li{counter-increment:lst-ctn-kix_list_15-1}.lst-kix_list_3-6>li:before{content:"" counter(lst-ctn-kix_list_3-6,decimal) ". "}.lst-kix_list_21-7>li:before{content:"" counter(lst-ctn-kix_list_21-7,decimal) ". "}ol.lst-kix_list_5-0.start{counter-reset:lst-ctn-kix_list_5-0 0}.lst-kix_list_11-2>li:before{content:"" counter(lst-ctn-kix_list_11-2,decimal) ". "}ol.lst-kix_list_12-4.start{counter-reset:lst-ctn-kix_list_12-4 0}.lst-kix_list_16-6>li:before{content:"" counter(lst-ctn-kix_list_16-6,decimal) ". "}ol.lst-kix_list_10-1.start{counter-reset:lst-ctn-kix_list_10-1 0}ol.lst-kix_638crpolklom-6.start{counter-reset:lst-ctn-kix_638crpolklom-6 0}.lst-kix_81qdu2dxiajy-8>li:before{content:"" counter(lst-ctn-kix_81qdu2dxiajy-8,lower-roman) ". "}.lst-kix_list_18-2>li{counter-increment:lst-ctn-kix_list_18-2}ol.lst-kix_list_5-6.start{counter-reset:lst-ctn-kix_list_5-6 0}.lst-kix_list_16-1>li:before{content:"" counter(lst-ctn-kix_list_16-1,decimal) ". "}.lst-kix_list_7-3>li{counter-increment:lst-ctn-kix_list_7-3}.lst-kix_list_19-3>li{counter-increment:lst-ctn-kix_list_19-3}.lst-kix_81qdu2dxiajy-5>li:before{content:"" counter(lst-ctn-kix_81qdu2dxiajy-5,lower-roman) ". "}ol.lst-kix_list_7-8.start{counter-reset:lst-ctn-kix_list_7-8 0}.lst-kix_list_12-4>li{counter-increment:lst-ctn-kix_list_12-4}ol.lst-kix_list_10-2.start{counter-reset:lst-ctn-kix_list_10-2 0}.lst-kix_list_12-7>li{counter-increment:lst-ctn-kix_list_12-7}.lst-kix_list_17-2>li:before{content:"" counter(lst-ctn-kix_list_17-2,decimal) ". "}ol.lst-kix_list_5-5.start{counter-reset:lst-ctn-kix_list_5-5 0}ol.lst-kix_list_17-3.start{counter-reset:lst-ctn-kix_list_17-3 0}.lst-kix_list_17-5>li:before{content:"" counter(lst-ctn-kix_list_17-5,decimal) ". "}.lst-kix_list_6-2>li{counter-increment:lst-ctn-kix_list_6-2}.lst-kix_638crpolklom-4>li{counter-increment:lst-ctn-kix_638crpolklom-4}.lst-kix_list_7-1>li:before{content:"" counter(lst-ctn-kix_list_7-1,decimal) ". "}.lst-kix_list_13-5>li{counter-increment:lst-ctn-kix_list_13-5}.lst-kix_list_9-6>li{counter-increment:lst-ctn-kix_list_9-6}ol.lst-kix_list_5-4.start{counter-reset:lst-ctn-kix_list_5-4 0}ol.lst-kix_638crpolklom-7.start{counter-reset:lst-ctn-kix_638crpolklom-7 0}ol.lst-kix_list_5-1.start{counter-reset:lst-ctn-kix_list_5-1 0}.lst-kix_wg014qgjj4p4-2>li:before{content:"" counter(lst-ctn-kix_wg014qgjj4p4-2,lower-roman) ". "}.lst-kix_list_20-3>li{counter-increment:lst-ctn-kix_list_20-3}.lst-kix_list_16-6>li{counter-increment:lst-ctn-kix_list_16-6}.lst-kix_list_11-6>li{counter-increment:lst-ctn-kix_list_11-6}ol.lst-kix_list_10-0.start{counter-reset:lst-ctn-kix_list_10-0 0}.lst-kix_638crpolklom-1>li:before{content:"" counter(lst-ctn-kix_638crpolklom-1,lower-latin) ". "}ol.lst-kix_list_17-8.start{counter-reset:lst-ctn-kix_list_17-8 0}.lst-kix_81qdu2dxiajy-2>li{counter-increment:lst-ctn-kix_81qdu2dxiajy-2}.lst-kix_list_3-8>li{counter-increment:lst-ctn-kix_list_3-8}.lst-kix_list_4-6>li{counter-increment:lst-ctn-kix_list_4-6}.lst-kix_list_1-5>li{counter-increment:lst-ctn-kix_list_1-5}ol.lst-kix_list_17-5.start{counter-reset:lst-ctn-kix_list_17-5 0}.lst-kix_list_4-2>li:before{content:"" counter(lst-ctn-kix_list_4-2,decimal) ". "}.lst-kix_list_17-4>li{counter-increment:lst-ctn-kix_list_17-4}.lst-kix_list_15-2>li:before{content:"" counter(lst-ctn-kix_list_15-2,decimal) ". "}.lst-kix_list_10-8>li{counter-increment:lst-ctn-kix_list_10-8}.lst-kix_list_10-6>li:before{content:"" counter(lst-ctn-kix_list_10-6,decimal) ". "}.lst-kix_list_9-1>li:before{content:"" counter(lst-ctn-kix_list_9-1,decimal) ". "}ol.lst-kix_list_12-7.start{counter-reset:lst-ctn-kix_list_12-7 0}.lst-kix_list_15-8>li{counter-increment:lst-ctn-kix_list_15-8}ol.lst-kix_list_12-8.start{counter-reset:lst-ctn-kix_list_12-8 0}.lst-kix_list_20-3>li:before{content:"" counter(lst-ctn-kix_list_20-3,decimal) ". "}.lst-kix_list_21-1>li{counter-increment:lst-ctn-kix_list_21-1}.lst-kix_list_10-1>li{counter-increment:lst-ctn-kix_list_10-1}.lst-kix_list_8-8>li{counter-increment:lst-ctn-kix_list_8-8}ol.lst-kix_list_17-6.start{counter-reset:lst-ctn-kix_list_17-6 0}.lst-kix_list_1-6>li:before{content:"" counter(lst-ctn-kix_list_1-6,decimal) ". "}.lst-kix_list_12-6>li:before{content:"" counter(lst-ctn-kix_list_12-6,decimal) ". "}.lst-kix_list_2-2>li:before{content:"" counter(lst-ctn-kix_list_2-2,lower-roman) ". "}.lst-kix_list_13-2>li:before{content:"" counter(lst-ctn-kix_list_13-2,decimal) ". "}ol.lst-kix_list_5-2.start{counter-reset:lst-ctn-kix_list_5-2 0}ol{margin:0;padding:0}table td,table th{padding:0}.c1{-webkit-text-decoration-skip:none;color:#954f72;font-weight:400;text-decoration:underline;text-decoration-skip-ink:none;font-size:10pt;font-family:"Times New Roman";font-style:italic}.c2{padding-top:14pt;padding-bottom:8pt;line-height:1.0;orphans:2;widows:2;text-align:justify;height:9pt}.c17{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Linux Libertine";font-style:normal}.c46{background-color:#fffffe;padding-top:0pt;padding-bottom:0pt;line-height:1.2954545454545454;orphans:2;widows:2;text-align:left}.c11{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Linux Libertine";font-style:normal}.c19{padding-top:14pt;padding-bottom:8pt;line-height:1.0;orphans:2;widows:2;text-align:center;height:9pt}.c36{background-color:#ffffff;padding-top:0pt;padding-bottom:0pt;line-height:1.254545428536155;orphans:2;widows:2;text-align:justify}.c43{background-color:#fffffe;padding-top:0pt;padding-bottom:0pt;line-height:1.2954545454545454;orphans:2;widows:2;text-align:justify}.c13{padding-top:0pt;padding-bottom:0pt;line-height:1.0999999999999999;orphans:2;widows:2;text-align:justify;height:9pt}.c48{margin-left:28pt;padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c58{background-color:#ffffff;padding-top:0pt;padding-bottom:8pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Linux Biolinum";font-style:italic}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Linux Biolinum";font-style:normal}.c20{padding-top:0pt;padding-bottom:8pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c65{padding-top:0pt;padding-bottom:0pt;line-height:1.0999999999999999;orphans:2;widows:2;text-align:center}.c33{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:justify}.c44{padding-top:0pt;padding-bottom:8pt;line-height:1.070000019940463;orphans:2;widows:2;text-align:justify}.c16{padding-top:11pt;padding-bottom:2pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c27{padding-top:9pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c14{padding-top:3pt;padding-bottom:3pt;line-height:1.0999999999999999;orphans:2;widows:2;text-align:justify}.c8{padding-top:0pt;padding-bottom:8pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c55{padding-top:11pt;padding-bottom:2pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c38{padding-top:0pt;padding-bottom:10pt;line-height:1.1500000000000001;orphans:2;widows:2;text-align:left}.c35{padding-top:10pt;padding-bottom:1pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c52{padding-top:19pt;padding-bottom:4pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c67{padding-top:11pt;padding-bottom:0pt;line-height:1.0999999999999999;orphans:2;widows:2;text-align:justify}.c50{padding-top:19pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c42{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c59{padding-top:14pt;padding-bottom:8pt;line-height:1.0;orphans:2;widows:2;text-align:center}.c45{padding-top:3pt;padding-bottom:3pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c4{padding-top:0pt;padding-bottom:8pt;line-height:1.070000019940463;orphans:2;widows:2;text-align:center}.c61{padding-top:2pt;padding-bottom:5pt;line-height:1.0;orphans:2;widows:2;text-align:center}.c53{padding-top:10pt;padding-bottom:2pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c34{padding-top:9pt;padding-bottom:4pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c6{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c57{padding-top:6pt;padding-bottom:3pt;line-height:1.0999999999999999;orphans:2;widows:2;text-align:center}.c18{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Linux Libertine";font-style:normal}.c37{padding-top:0pt;padding-bottom:0pt;line-height:1.0999999999999999;orphans:2;widows:2;text-align:justify}.c47{padding-top:0pt;padding-bottom:10pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c30{font-weight:400;text-decoration:none;font-size:9pt;font-family:"Linux Biolinum";font-style:normal}.c12{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c40{padding-top:0pt;padding-bottom:0pt;line-height:1.1500000000000001;text-align:left}.c63{font-weight:700;font-size:10.5pt;font-family:"Courier New"}.c41{font-size:17.5pt;font-family:"Linux Biolinum";font-weight:700}.c56{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c54{text-decoration:none;vertical-align:baseline;font-style:normal}.c9{font-family:"Linux Biolinum";font-style:italic;font-weight:400}.c39{color:inherit;text-decoration:inherit}.c23{font-size:11pt;font-weight:700}.c10{text-indent:12pt;height:9pt}.c66{font-weight:700;font-family:"Linux Libertine"}.c62{font-weight:400;font-family:"Calibri"}.c64{color:#24292f;font-family:"Arial"}.c31{font-family:"Linux Biolinum";font-weight:400}.c26{margin-left:15pt;text-indent:-15pt}.c49{font-family:"Times New Roman";font-weight:400}.c21{height:9pt}.c22{font-size:12pt}.c3{font-size:10pt}.c29{font-size:11pt}.c15{font-size:7pt}.c24{color:#000000}.c28{margin-right:18pt}.c60{vertical-align:baseline}.c32{font-style:italic}.c7{vertical-align:super}.c25{text-indent:12pt}.c51{font-size:8pt}.title{padding-top:0pt;color:#17365d;border-bottom-color:#4f81bd;border-bottom-width:1pt;font-size:26pt;padding-bottom:4pt;font-family:"Cambria";line-height:1.0999999999999999;border-bottom-style:solid;orphans:2;widows:2;text-align:justify}.subtitle{padding-top:6pt;color:#000000;font-size:12pt;padding-bottom:3pt;font-family:"Linux Biolinum";line-height:1.0999999999999999;orphans:2;widows:2;text-align:center}li{color:#000000;font-size:9pt;font-family:"Linux Libertine"}p{margin:0;color:#000000;font-size:9pt;font-family:"Linux Libertine"}h1{padding-top:24pt;color:#366091;font-weight:700;font-size:14pt;padding-bottom:0pt;font-family:"Cambria";line-height:1.0999999999999999;page-break-after:avoid;orphans:2;widows:2;text-align:justify}h2{padding-top:10pt;color:#0070c0;font-weight:700;font-size:13pt;padding-bottom:0pt;font-family:"Cambria";line-height:1.0999999999999999;page-break-after:avoid;orphans:2;widows:2;text-align:justify}h3{padding-top:10pt;color:#943734;font-weight:700;font-size:9pt;padding-bottom:0pt;font-family:"Cambria";line-height:1.0999999999999999;page-break-after:avoid;orphans:2;widows:2;text-align:justify}h4{padding-top:10pt;color:#943734;font-size:9pt;padding-bottom:0pt;font-family:"Cambria";line-height:1.0999999999999999;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:justify}h5{padding-top:10pt;color:#4f6228;font-weight:700;font-size:10pt;padding-bottom:0pt;font-family:"Cambria";line-height:1.0999999999999999;page-break-after:avoid;orphans:2;widows:2;text-align:justify}h6{padding-top:0pt;color:#000000;font-size:12pt;padding-bottom:12pt;font-family:"Times New Roman";line-height:1.0999999999999999;page-break-after:avoid;orphans:2;widows:2;text-align:justify}</style></head><body class="c56 doc-content"><p class="c21 c40"><span class="c11"></span></p><p class="c61"><span class="c41">Code Completion Using Machine Learning</span></p><p class="c57 subtitle"><span class="c54 c31 c22 c24">An overview of modern methods</span></p><p class="c59"><span class="c22">Aaron Davis</span><span class="c22 c24"><br></span><span class="c3 c24">&nbsp;</span><span class="c3">Data Science</span><span class="c3 c24"><br></span><span class="c3">University of Colorado</span><span class="c3 c24"><br> </span><span class="c3">Boulder, CO, USA</span><span class="c3 c24"><br> </span><span class="c12 c3"><a class="c39" href="mailto:aada4270@colorado.edu">aada4270@colorado.edu</a></span><span class="c3">&nbsp;</span></p><p class="c19"><span class="c18 c22"></span></p><p class="c59"><span class="c22">Darsh Shah</span><span class="c22 c24"><br></span><span class="c3 c24">&nbsp;</span><span class="c3">&nbsp;Data Science</span><span class="c3 c24"><br> </span><span class="c3">University of Colorado<br> Boulder, CO, USA</span><span class="c3 c24"><br></span><span class="c12 c3"><a class="c39" href="mailto:darsh.shah@colorado.edu">darsh.shah@colorado.edu</a></span><span class="c3">&nbsp;</span></p><p class="c59"><span class="c22">Faizan Husain</span><span class="c22 c24"><br></span><span class="c3 c24">&nbsp;</span><span class="c3">&nbsp;Data Science</span><span class="c3 c24"><br> </span><span class="c3">University of Colorado<br> Boulder, CO, USA</span><span class="c3 c24"><br></span><span class="c3 c12"><a class="c39" href="mailto:fahu8845@colorado.edu">fahu8845@colorado.edu</a></span><span class="c3">&nbsp;</span></p><p class="c19"><span class="c18 c3"></span></p><p class="c59"><span class="c22">Spriha Awasthi</span><span class="c22 c24"><br></span><span class="c3 c24">&nbsp;</span><span class="c3">&nbsp;Data Science</span><span class="c3 c24"><br></span><span class="c3">University of Colorado<br> Boulder, CO, USA </span><span class="c12"><br><a class="c39" href="mailto:spriha.awasthi@colorado.edu">spriha.awasthi@colorado.edu</a></span></p><p class="c2"><span class="c18 c22"></span></p><p class="c21 c38"><span class="c54 c29 c24 c62"></span></p><p class="c52"><span class="c23">Abstract</span></p><p class="c37"><span>During this project, we focus on creating better code autocompletion for Python IDEs using machine learning. &nbsp;The specific methods we use are n-gram code completion, RNN and LSTM code completion, and Transformer networks for code completion. &nbsp;The primary result of this project is an LSTM network that achieved 86% accuracy on a validation dataset. &nbsp;The conclusion of this project is that using machine learning for code completion is a fairly difficult task, but the results justify the time and effort required.</span></p><p class="c52"><span class="c29 c24">1</span><span class="c23 c24">&nbsp;</span><span class="c23">Introduction</span></p><p class="c6"><span class="c11">The data scientist role is not primarily a programming role. &nbsp;Rather, it is a role that requires deep analysis of data, the methods used to process that data, and the ways that value can be gained from that data. &nbsp;The goal of this project is to create a tool that helps data scientists who use Python to code more efficiently by providing recommendations for the next word, given the previous words in the code document. &nbsp;The working assumption is that a data scientist who can code more efficiently will have more time to think about what their code actually ought to be doing to gain maximum value from the data.</span></p><p class="c13"><span class="c11"></span></p><p class="c37"><span class="c17">CCS CONCEPTS</span></p><p class="c45"><span class="c11">&bull;&nbsp;Computing methodologies &bull;&nbsp;Machine Learning&nbsp;&nbsp; &bull;&nbsp;Machine Learning Approaches &bull;&nbsp;Learning Latent Representations</span></p><p class="c45 c21"><span class="c11"></span></p><p class="c35"><span class="c17">KEYWORDS</span></p><p class="c14"><span>Code completion, machine learning, neural networks, RNN, LSTM, Transformer networks, attention, encoder, class imbalance</span></p><p class="c67"><span class="c54 c24 c51 c66">ACM Reference format:</span></p><p class="c45"><span class="c51">Aaron Davis, Darsh Shah, Faizan Husain and Spriha Awasthi. 2022. Code Completion Using Machine Learning: An overview of modern methods.</span></p><p class="c52"><span class="c29">2</span><span class="c17">&nbsp;Related and Completed Work</span></p><p class="c34"><span class="c29">2.1</span><span class="c17">&nbsp;Data Preprocessing</span></p><p class="c36"><span>The Project CodeNet Dataset consists of a very large collection of source files, extensive metadata, tooling to access the dataset and make tailored selections, and documentation. </span><span>It is a large-scale dataset with approximately 14 million code samples, each of which is an intended solution to one of 4000 coding problems. The code samples are written in over 50 programming languages (the dominant languages are C++, C, Python, and Java) and they are annotated with a rich set of information, such as its code size, memory footprint, cpu run time, and status, which indicates acceptance or error types.</span><span>&nbsp;The data and metadata are organized in a rigorous directory structure. At the top level sits the Project CodeNet directory with several sub-directories, data, metadata, and problem descriptions:</span><span>&nbsp;</span><span>data</span><span>&nbsp;is further subdivided into a directory per problem and within each problem directory, directories for each language. The language directory contains all the source files supposed to be written in that programming or scripting language. </span><span class="c11">Out of the vast dataset we used only python dataset and for the better accuracy of our prediction we used only the accepted codes solution.</span></p><p class="c43"><span class="c54 c24 c63">&nbsp; </span></p><p class="c46"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 331.50px; height: 83.30px;"><img alt="" src="images/image10.png" style="width: 331.50px; height: 83.30px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c36"><span class="c11">To create a custom dictionary, we must tokenize each element of the code. Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens. Since we are tokenizing code samples and not a text, we must create a filter which can break the code as per our interest. </span></p><p class="c36"><span class="c11">&nbsp;</span></p><p class="c43"><span>filters=</span><span class="c11">&#39;!&quot;#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~\t\n1234567890&#39;</span></p><p class="c43"><span class="c11">&nbsp;</span></p><p class="c43"><span class="c11">We used the above filter string with the python method split() to split it into each dictionary element. What it does is it will take each string item from our filter and create a list and save it to our dictionary.</span></p><p class="c44 c21"><span class="c11"></span></p><p class="c44"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 341.38px; height: 247.50px;"><img alt="" src="images/image9.png" style="width: 341.38px; height: 247.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c11">&nbsp;</span></p><p class="c8 c21"><span class="c11"></span></p><p class="c8"><span class="c11">The output of the above codes will give us a dictionary which contains all the tokenized code samples.</span></p><p class="c58"><span>We will use the above tokenized dictionary to train our tokenizer. For the training of the tokenizer we first start with all the characters present in the training corpus as tokens. Identify the most common pair of tokens and merge it into one token. Repeat until the number of tokens has reached the size we want.</span></p><p class="c34"><span class="c29">2.2</span><span class="c17">&nbsp;Creating Word Embeddings</span></p><p class="c6 c25"><span class="c9">2.2</span><span class="c32">.1</span><span class="c9">&nbsp;Summary of Word2Vec. </span><span class="c31">One of the best known methods for creating meaningful word embeddings is a method called Word2Vec, created by a team of researchers working at Google in 2013.</span><span class="c31 c7">[1] </span><span class="c5">&nbsp;</span></p><p class="c6 c25"><span class="c5">Word2Vec works by taking as input a text corpus which is used to create a dictionary of one-hot encoded words. &nbsp;For example, if the dictionary contains ten thousand words, and the fiftieth word is &ldquo;cat&rdquo;, then the word &ldquo;cat&rdquo; will be encoded as a vector of ten thousand zeros, except for a one in the fiftieth position.</span></p><p class="c6 c25"><span class="c5">The next step in the process is to create a vector that represents the context of the word in a particular sentence. &nbsp;For example, in the sentence &ldquo;The dog chased the cat&rdquo; the context words are &ldquo;dog&rdquo; and &ldquo;chased&rdquo;, and these can both be encoded in the same vector by summing the one-hot encodings of each of these words (using the same process as in the previous step). &nbsp;This new vector will be a context vector for the word &ldquo;cat&rdquo;. &nbsp;This process is repeated until all words and all contexts for each word have been converted to vectors. </span></p><p class="c6 c25"><span class="c5">Finally, a neural network is created that takes as input the word vector and attempts to output the context vector. &nbsp;The dimensionality of the hidden layers of the network are reduced from 10,000 at the input (in this example) to a much smaller dimension (200-300, for example), and then re-expanded to the original dimension to output the context vector. &nbsp;</span></p><p class="c6 c25"><span class="c5">This architecture forces the network to learn a dense encoding from the sparse inputs. &nbsp;The output of the last small-dimension hidden layer is then used as a vector to represent each word input into the neural network. &nbsp;This learned vector representation contains information about what contexts words appear in, essentially.</span></p><p class="c6 c25"><span class="c9">2.2</span><span class="c32">.2</span><span class="c9">&nbsp;Other Word Embedding Methods. &nbsp;</span><span class="c31">Two other well known word embedding techniques are singular value decomposition from a co-occurrence matrix</span><span class="c31 c7">[2]</span><span class="c31">, and word embeddings using the Transformer architecture.</span><span class="c7 c31">[3]</span><span class="c5">&nbsp;We currently plan to use the approach from 2.1.1 for any custom word embeddings done for this project, but that may change depending on available time and resources.</span></p><p class="c6 c25"><span class="c31">2.2.3 </span><span class="c9">Completed Word2Vec Work. &nbsp;</span><span class="c5">So far, we have trained our own word embeddings using several neural network structures in Keras using the methodology described in 2.1.1. &nbsp;</span></p><p class="c6 c25"><span class="c5">The first neural network architecture we used was an input layer (30,000 dimensional) into a hidden layer (300 dimensional with ReLU activation) into an output layer (30,000 dimensional). &nbsp;Using this architecture, we were able to create a 300 dimensional latent space that effectively predicted the correct word based on context with a 95% accuracy.</span></p><p class="c6 c25"><span class="c5">The second (more successful) neural network architecture had the same input and output layers, but the hidden layers were 3X hidden layers, each with 30 neurons (ReLU activation). &nbsp;This deeper network allowed us to create arguably better word embeddings, with a smaller dimensional latent space (30, instead of 300), while achieving higher accuracy (97.5%, instead of 95%).</span></p><p class="c6 c25"><span class="c5">To achieve this high of an accuracy, we trained the model for tens of thousands of epochs - an approach that is probably not advisable for most machine learning models this size because of the possibility of overfitting. &nbsp;In this case, though, the goal of our model was information compression, and our model would never see any &ldquo;new&rdquo; data other than what it was trained on, so the inability to generalize is not really a concern.</span></p><p class="c6 c25"><span class="c31">When we use these custom word embeddings in our RNN, LSTM, and Transformer models, we will compare the results with pre-trained word embedding models like GLoVE.</span></p><p class="c27"><span class="c29">2.3</span><span class="c17">&nbsp;N-gram Code Completion</span></p><p class="c8"><span>Models that assign probabilities to sentences or sequences of words and can be used to find the most likely continuation of a sequence, are called language models. Among them, is the n-gram language model, which assigns probabilities to sequences out of n words, called the n-grams. A one-word sequence is a unigram, pairs of words are referred to as 2-grams or bigrams, 3-grams or trigrams are sequences of three words, and so on.</span><span class="c7">[7]</span><span class="c11">&nbsp;Examples of bigrams might be &quot;he ate&quot;, &quot;ate the&quot;, &quot;the whole&quot; and &quot;whole pizza&quot;, whereas trigrams would look like &quot;he ate the&quot;, &quot;ate the whole&quot;, and &quot;the whole pizza&quot;.</span></p><p class="c8"><span>To describe the conditional probability of a word </span><span class="c32">w</span><span>&nbsp;based on history </span><span class="c32">h</span><span class="c11">, we use the following notation:</span></p><p class="c20"><span>P(</span><span class="c32">w </span><span>| </span><span class="c32">h</span><span class="c11">)</span></p><p class="c8"><span class="c11">Here is a more concrete example: if we have a sentence &quot;he ate the whole pizza&quot;, and want to compute the probability of the word &quot;pizza&quot; given that the previous words are &quot;he ate the whole&quot;, we can express it as a conditional probability:</span></p><p class="c20"><span class="c11">P(pizza|he ate the whole)</span></p><p class="c8"><span class="c11">To estimate this probability, we can use relative frequency: we need to compute the number of occurrences of &quot;he ate the whole&quot;, as well the number of occurrences of the sentence &quot;he ate the whole pizza&quot;, and divide the latter by the former:</span></p><p class="c20"><span class="c11">P(pizza|he ate the whole) </span></p><p class="c20"><span>= C(he ate the whole pizza) / C(he ate the whole)</span></p><p class="c6 c25"><span class="c31">2.3.1 </span><span class="c9">Completed N-gram Work. </span><span class="c11">We created a simple pipeline function which splits the dataset by the &lt;EOS&gt; sample token. This &lt;EOS&gt; token suggests that it is the end of a particular code block. We also remove leading and trailing spaces and tokenize each word of code using nltk.word_tokenize.</span></p><p class="c6 c10"><span class="c11"></span></p><p class="c8"><span class="c11">We then split our tokenized code samples into training, testing and validation sets. As our dataset is quite big, we only used those words that appear k times in our dataset. For this, we created a function that creates a frequency dictionary.</span></p><p class="c8"><span class="c11">To enable the model to handle code tokens that are not present in the training corpus, we created a closed_vocabulary containing only those code tokens according to the count_threshold parameter. </span></p><p class="c25 c65"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 172.50px; height: 281.31px;"><img alt="" src="images/image1.png" style="width: 172.50px; height: 281.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span class="c11">Tokenized Code samples</span></p><p class="c44 c21"><span class="c11"></span></p><p class="c8"><span class="c11">We then add &lt;unk&gt; tokens to those code tokens which are not there in the closed_vocabulary. </span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 150.50px; height: 206.50px;"><img alt="" src="images/image13.png" style="width: 150.50px; height: 206.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c20"><span class="c11">Final Training Corpus which contains &lt;unk&gt; tokens.</span></p><p class="c8"><span class="c11">This function calculates the priority of the next token given our previous n-gram:</span></p><p class="c8"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.00px; height: 54.67px;"><img alt="" src="images/image4.png" style="width: 320.00px; height: 54.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8"><span class="c11">We had to consider what if we came across a n-gram that wasn&rsquo;t in the training set. Then our denominator in the above function would be zero and our definition for the probability would become invalid. Thus, we use k-smoothing, which adds a positive constant k to each numerator and &nbsp;k&times;|V| &nbsp;in the denominator, where &nbsp;|V| &nbsp;is the number of words in the vocabulary. This ensures any n-gram with zero count has the same probability of 1 / |V|. Thus, our original estimation gets modified to: </span></p><p class="c8"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.00px; height: 58.67px;"><img alt="" src="images/image7.png" style="width: 320.00px; height: 58.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c44"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.00px; height: 117.33px;"><img alt="" src="images/image11.png" style="width: 320.00px; height: 117.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c3 c32 c49">&nbsp;Reference</span><span class="c49 c3 c32 c7">[13]</span><span class="c49 c3 c32">:</span><span class="c1"><a class="c39" href="https://www.google.com/url?q=https://www.kaggle.com/sauravmaheshkar/auto-completion-using-n-gram-models&amp;sa=D&amp;source=editors&amp;ust=1671744182215148&amp;usg=AOvVaw1GKHUWN4rCCBEd0kJM3lv3">https://www.kaggle.com/sauravmaheshkar/auto-completion-using-n-gram-models</a></span></p><p class="c6 c10"><span class="c0"></span></p><p class="c8"><span>We can see that for the input of &ldquo;for i in&rdquo;, the n-gram model outputs the top 10 suggestions with &ldquo;range&rdquo; as having the highest probability. This makes sense because when we write a for loop, we usually write it as &ldquo;for i &nbsp;in range(0, 10)&rdquo;</span></p><p class="c27"><span class="c29">2.4</span><span class="c17">&nbsp;RNN Code Completion</span></p><p class="c6 c25"><span class="c9">2.4</span><span class="c32">.1</span><span class="c9">&nbsp;Summary of Recurrent Neural Networks. </span><span class="c31">Recurrent neural networks (also known as RNNs) pass some knowledge about the previous time step into the neural network processing for the current time step. &nbsp;This approach was used to build Pythia, a code completion tool built in to Intellicode (an extension for Visual Studio Code).</span><span class="c30 c24 c7">[4]</span></p><p class="c6 c21"><span class="c24 c7 c30"></span></p><p class="c6"><span class="c9">&nbsp; &nbsp; &nbsp;2.4</span><span class="c32">.1</span><span class="c9">&nbsp;Implementation of Recurrent Neural Networks. </span><span class="c5">Before the implementation of recurrent neural networks, we first define the inputs/outputs design for training these networks. Overall, we model the entire dataset as a sequence of tokens and aim to predict the next token. For each token, we consider the last 10 tokens as context because programs should not have a longer context of narrative like spoken languages. </span></p><p class="c6 c21"><span class="c5"></span></p><p class="c6"><span class="c5">&nbsp; Before creating the table for this design, we generated tokens corresponding to different code text using python interpreter tokenization tools. It is essential that we do so because token s in natural languages can be generated by Tensorflow&rsquo;s SDK tools based on spaces, but it&rsquo;s not possible on programming languages because the grammar is different which is understandable to the compiler. The unique set of tokens generated are over ~200000 which includes variable names, operators and comments. </span></p><p class="c6 c21"><span class="c5"></span></p><p class="c47"><span class="c5">&nbsp; Then we split the entire corpus as a table of X1..X10 inputs and Y as output, where X1 to X10 are 10 previous tokens or an empty string if there was none. This defines the input layer of our neural network based designs as shown in Fig.2.4.1.1.</span></p><p class="c47"><span class="c5">&nbsp; Next we build a Vanilla RNN containing 256 nodes, with 2 dense feed forward layers of 256 nodes, dropout regularization and Relu activation. The last layer gives Softmax output for us to be able to predict a token from the most commonly used tokens of the corpus vocabulary. This makes it a context aware prediction for code completion rather than simply completing the word or template as in IDE level code completion.</span></p><p class="c6"><span class="c5">&nbsp; The accuracy we get is ~75% which could be further improved by fine tuning the network.</span></p><p class="c6"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.00px; height: 377.33px;"><img alt="" src="images/image2.png" style="width: 320.00px; height: 377.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.00px; height: 246.67px;"><img alt="" src="images/image12.png" style="width: 320.00px; height: 246.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6 c21"><span class="c5"></span></p><p class="c42"><span class="c5">Fig.2.4.1.1 &nbsp;Sample tables created and their translation predictions mapped from tokens to code</span></p><p class="c6 c21"><span class="c5"></span></p><p class="c6 c21"><span class="c5"></span></p><p class="c6"><span class="c9">&nbsp; &nbsp; &nbsp;2.4</span><span class="c32">.2</span><span class="c9">&nbsp;Weaknesses of Recurrent Neural Networks. </span><span class="c5">Basic RNNs suffer from the vanishing gradient problem. &nbsp;To rephrase, this means that the network can only remember so far back in time. &nbsp;If an important event occurred in a text series 1000 words ago, the RNN would likely not be able to remember that event long enough to make the connection to the current event. &nbsp;Long Short Term Memory (LSTM) models try to fix this problem.</span></p><p class="c6 c21"><span class="c5"></span></p><p class="c27"><span class="c29">2.5</span><span class="c17">&nbsp;LSTM Code Completion</span></p><p class="c8"><span class="c5">In [9], the team decided to train a machine learning model to sort completions from a code completion library rather than have the model generate the completion itself. They decided on doing this because some code completion libraries complete one keyword at a time ensuring that completions are syntactically correct. In order for them to use the dataset quickly, they created a new ML pipeline which takes a python library and transforms it into a dataset suitable for their model. Their best performing model takes two inputs, 40 latest tokens from the code written so far and a completion from Jedi: an open source static analysis tool written in Python for Python with a focus on code completion.</span></p><p class="c27"><span class="c31">In order to sort the completions from Jedi, they created a model that performs binary classifications on the completions. Since their model will return scores between 0 and 1, they are able to sort the jedi completions based on the score that their model gives.</span></p><p class="c8"><span class="c5">&nbsp; Upon evaluation, they found that the JEDI LSTM Sorter model required a person to put in 80% of the keystrokes to achieve a significantly decent code completion. However, the probability of achieving the top 3 completions was 90% which is significantly high in comparison to the traditional JEDI model.</span></p><p class="c8"><span class="c5">&nbsp; In [10], they define how a standard LSTM works and how traditional RNN suffer from hidden state bottleneck which is where all the information about the current sequence is composed into a fixed sized vector. In order to mitigate this problem, they propose an attention mechanism which is incorporated into the traditional LSTM. They keep an external memory of previous hidden states. At a certain point of time, the model uses an attention layer to compute the relation between the previous states and the hidden states. The model then produces a summary context vector. With the attention of LSTM, they received an accuracy of 80.6% in comparison to Vanilla LSTM with an accuracy of 79% in completion of Python based code.</span></p><p class="c8"><span class="c5">In [11], they also tried to implement LSTM and RNN where they use a dense layer after the GRU cell to get the scores for each output token. However, they did not achieve good accuracy with the LSTM model.</span></p><p class="c6"><span class="c9">&nbsp;2.4</span><span class="c32">.1</span><span class="c0">&nbsp;Implementation of LSTM Networks.</span></p><p class="c6 c21"><span class="c5"></span></p><p class="c6"><span class="c5">The implementation of LSTM is similar to that of RNN. For building the model architecture, we used the same set of hyper parameters as we did for RNN. We also attempted to predict as a classification problem over the entire corpus tokens set instead of selecting the most frequently occurring elements as is the practice in text completion when dealing with natural languages. This is because of the sparse distribution of the tokens. For completing phrases such as variable names, we can no longer rely on the most commonly spoken textual tokens, rather we need to be aware of the context and pick up the most recently used variable/method name as the case may be. We want our network to be aware of such context. This brings in challenges of training the network, because of the size of the data and computation resources that are expensive on larger models and data sizes. &nbsp;</span></p><p class="c6 c21"><span class="c5"></span></p><p class="c6"><span class="c5">With the above hypothesis, we build the LSTM network with inputs first passing tokens to a trainable embedding unlike a pre-trained word embedding layer of 32 dimension. This further forwards to an LSTM layer containing 256 nodes. And finally, we add 2 dense feed forward layers of 256 nodes each, dropout regularization and Relu activation is used just as in Vanilla RNN. The last layer gives Softmax output for us to be able to predict a token from the entire token corpus which is approximately ~200000 . </span></p><p class="c6 c21"><span class="c5"></span></p><p class="c6"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.00px; height: 313.33px;"><img alt="" src="images/image6.png" style="width: 320.00px; height: 313.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6 c21"><span class="c5"></span></p><p class="c6 c21"><span class="c5"></span></p><p class="c6"><span class="c31">We trained on 20 epochs and got 84.1% accuracy which is great performance on a set of this size. While this performance is great on its own, there could be further variations to beat this. However, Each epoch took around 3-4 hours and due to resource constraints, we could not experiment with more sets of hyperparameters and acknowledge it as a part of our future work. </span></p><p class="c27"><span class="c29">2.6</span><span class="c17">&nbsp;Transformer Code Completion</span></p><p class="c6 c25"><span class="c31">2.6.1 </span><span class="c9">Summary of Transformer Networks.</span><span class="c23">&nbsp; </span><span class="c5">Transformers were introduced in 2017 by Google Brain in [12] and have been, in direct or indirect way, the preferred model for NLP applications, replacing the more traditional &nbsp;RNN and its variants such as LSTM or GRUs. As an only attention based model, without RNN layers the transformers are capable of having extremely long term memory. They overcome sequential dependency of RNNs and also tackle its vanishing gradient difficulty. They allow for processing phrases in any order and provide meaning by focusing on context around it. This ability allows training to be parallelizable and we can process much larger datasets that were hard to do before. A direct consequence of this ability has led to evolution of pre-trained models like BERT ((Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer) on wikipedia corpus which are used in production by Google search.</span></p><p class="c6 c10"><span class="c5"></span></p><p class="c6 c25"><span class="c5">The transformers consist of several layers and are expensive to build on large sentences. The layers are grouped into 2 categories: encoder and decoder. The encoder takes in word embeddings from input text and adds positional encodings. Then a multi-head attention layer computes attention weights which are then passed to feed forward layers. The output of this encoder is then passed to decoder which combines the encoder&rsquo;s output to target text&rsquo;s word embeddings and positional encodings. Below is the architecture proposed by authors in [12].</span></p><p class="c27 c21"><span class="c11"></span></p><p class="c6 c25"><span class="c31">2.6.2 </span><span class="c9">Completed Transformers Work. </span><span class="c5">We&rsquo;ve attempted to train both a complete transformer model (following the above figure), and just the decoder section (see the left side of the above figure). &nbsp;The transformer model was attempting to predict which token (out of the 10,000 most common tokens) was most likely to occur next. &nbsp;We have not yet decided if limiting the possible outputs to the top 10,000 most frequent tokens was a good idea or not. &nbsp;When training our RNN and LSTM models, we did not limit the dictionary size to 10,000. Both models reported a ~75% training accuracy and a ~90% training top-5 accuracy. &nbsp;When testing the models, though, both seemed extremely biased towards predicting newline characters as the next token. &nbsp;This makes sense, given that the newline character is one of the most frequent tokens used during coding in Python.</span></p><p class="c6 c21"><span class="c5"></span></p><p class="c6 c10"><span class="c5"></span></p><p class="c27"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 337.50px; height: 408.12px;"><img alt="" src="images/image5.png" style="width: 337.50px; height: 408.12px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6 c10"><span class="c5"></span></p><p class="c6 c25"><span class="c5">While we did not have time to fix this issue, we did begin working on a few ideas for solutions. &nbsp;The most obvious solution idea is to weight each token in the loss function so that incorrectly classifying a newline character has less negative impact than incorrectly classifying an &ldquo;if-then&rdquo; statement. &nbsp;The most straightforward method for reweighting classes is to reweight classes based on frequency so that the least common classes contribute the most to the loss when misclassified, while common token classes (like the newline character) contribute very little to the loss when misclassified. &nbsp;The problem with this approach is that we don&rsquo;t want to severely punish our model for missing some obscure token, but reweighting the model in this way would do exactly that.</span></p><p class="c6 c10"><span class="c5"></span></p><p class="c6 c25"><span class="c5">We also worked with the idea of just dropping the first two most popular tokens (newline and unknown tokens) from our predictions completely, given that both of these predictions provide minimal value to the programmer while also severely skewing our class balance. &nbsp;This idea was worked with briefly, but we were not able to pursue it further due to time constraints.</span></p><p class="c6 c10"><span class="c5"></span></p><p class="c6 c25"><span class="c5">See the following image for the Transformer encoder (left half) architecture:</span></p><p class="c6 c10"><span class="c5"></span></p><p class="c25 c42"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 312.52px; height: 567.50px;"><img alt="" src="images/image3.png" style="width: 312.52px; height: 567.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6 c10"><span class="c5"></span></p><p class="c6 c10"><span class="c5"></span></p><p class="c6 c25"><span class="c31">2.6.3 </span><span class="c9">Lessons Learned from Transformers. &nbsp;</span><span class="c5">While our transformer models were not particularly successful on testing data, we did learn a lot about transformer networks during our project. &nbsp;Two key parts of what makes transformer networks successful are the use of self attention layers and positional embeddings to preserve sequence.</span></p><p class="c6 c25"><span class="c5">To sum up, self attention layers compare each item (in this case, word) in a sequence to every other item in that sequence. &nbsp;This allows the model to learn how important every other word is in predicting the word it is currently focusing on. &nbsp;Positional embeddings are added to the token embeddings so that the order of the sequence can be understood by the attention layer. &nbsp;Without this summation, the model is order-agnostic, which would obviously not be good for a text generation or code completion model.</span></p><p class="c6 c25"><span class="c31">For more helpful information about Transformer networks, we highly recommend reading &ldquo;Attention is All You Need&rdquo; </span><span class="c31 c7">[12]</span><span class="c31">.</span></p><p class="c50"><span class="c29">3</span><span class="c17">&nbsp;Conclusion</span></p><p class="c50"><span>Next we present some of the major results and observations from comparing the different experiments.</span></p><p class="c27"><span class="c29">3.1</span><span class="c17">&nbsp;Project Description</span></p><p class="c6 c25"><span class="c9">3.1</span><span class="c32">.1</span><span class="c9">&nbsp;Project Summary. </span><span class="c11">We worked to replicate each section of the related work, some sections being more successful than others. &nbsp;We used an n-gram code completion model as the baseline to compare all other techniques to. The goal is to find the next word in a sequence, given the preceding text. &nbsp;The specific programming language we&rsquo;re focusing on is Python, though these same techniques should apply seamlessly to other languages.</span></p><p class="c6 c25"><span class="c9">3.1</span><span class="c32">.2</span><span class="c9">&nbsp;Proposed Dataset. &nbsp;</span><span class="c31">The dataset we used is the IBM CodeNet dataset</span><span class="c31 c7">[5]</span><span class="c31">&nbsp;which includes millions of code samples from C++, Python, and several other less common languages. &nbsp;These additional languages could come in useful for creating models that </span></p><p class="c27"><span class="c29">3.2</span><span class="c17">&nbsp;Goal Conclusions</span></p><p class="c6 c25"><span class="c9">3.2</span><span class="c32">.1</span><span class="c9">&nbsp;First Goal.</span><span class="c23">&nbsp;</span><span class="c11">The goal of the project has been two-fold. &nbsp;First and primarily, we wanted to recreate past successful code completion methods. &nbsp;This goal has been achieved with n-gram, RNN, and LSTM code completion methods. &nbsp;Transformer networks require additional work before we can consider that goal met for that type of network.</span></p><p class="c6 c25"><span class="c9">3.2</span><span class="c32">.1</span><span class="c9">&nbsp;Second Goal. </span><span class="c11">Second, we wanted to be able to clearly explain each method used. &nbsp;We believe this second goal has been a success for everyone involved in the project.</span></p><p class="c21 c50"><span class="c18 c29"></span></p><p class="c50"><span class="c29">4</span><span class="c17">&nbsp;Model Evaluation</span></p><p class="c6"><span>We withheld a portion of the CodeNet python dataset to use as a validation and testing dataset. &nbsp;The evaluation metric used was accuracy, like used in previous code completion projects.</span><span class="c7">[4] </span><span>&nbsp; Our LSTM model achieved an accuracy of </span><span class="c11">86.23% on a validation dataset, beating our RNN model by 11.5%. &nbsp;On the 20th epoch, when training ended for our LSTM model the accuracy was still increasing, as can be seen in the following plot:</span></p><p class="c6"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.00px; height: 241.33px;"><img alt="" src="images/image8.png" style="width: 320.00px; height: 241.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6"><span class="c11">This trend strongly indicates that there is future room for improvement in both of these models, but particularly with the LSTM model.</span></p><p class="c6 c21"><span class="c11"></span></p><p class="c6"><span>Given the issues with the transformer models, we do not have a final model accuracy worth sharing. &nbsp;That part of the project is far too incomplete, and requires a good deal of further work before good results can be expected.</span></p><p class="c50"><span class="c29">5</span><span class="c17">&nbsp;Future Work</span></p><p class="c16"><span class="c11">There are several big things that would make good additions to this project that we&rsquo;re aware of. &nbsp;</span></p><p class="c16"><span class="c11">1) Increasing the breadth of our Python dataset is a good first step. &nbsp;The IBM dataset is composed of code meant to solve a fairly limited set of problems. &nbsp;Expanding this dataset to include a larger set of solved problems would be a good starting point.</span></p><p class="c16"><span class="c11">&nbsp;2) A good second step to work on would be improving the transformer networks and working on solving the class imbalance problem. &nbsp;Given that transformer networks are state of the art for sequence generation models, we believe that the issues we&rsquo;re having with them are not due to the model structure, but are rather due to our use of the models and our data preprocessing.</span></p><p class="c16"><span class="c11">3) Further work with model architecture tuning and hyperparameter tuning could help improve our working models even further. &nbsp;Striking a balance between model size, model accuracy, and avoiding overfitting is a surprisingly difficult task. &nbsp;This step is potentially very resource intensive.</span></p><p class="c16"><span class="c11">4) Pre-formatting the code we&rsquo;re training on to PEP-8 could help with data preprocessing by removing inconsistencies in our dataset.</span></p><p class="c16"><span class="c11">5) We would like to expand our work to other common programming languages (Java, C++, Go, JavaScript, etc.). &nbsp;Once data preprocessing is complete for each language, this process should be fairly straightforward, as it will be primarily focused on waiting for the same model architectures to train on different datasets.</span></p><p class="c16"><span class="c11">6) Another interesting possible use-case for Transformer networks is for translating code from one coding language to another (i.e. Java to Python). &nbsp;Given that Transformers are frequently used for language translation, this use-case seems entirely plausible.</span></p><p class="c16"><span class="c11">7) Finally, we would like to deploy our code completion models as add-ons for integrated development environments after we&rsquo;ve ironed out the small set of issues that we&rsquo;re having.</span></p><p class="c53"><span class="c17">REFERENCES</span></p><p class="c6 c26"><span class="c15 c24">[1]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c15">Mikolov, Tomas, et al. &quot;Efficient estimation of word representations in vector space.&quot; </span><span class="c15">arXiv preprint arXiv:1301.3781</span><span class="c15">&nbsp;(2013).</span></p><p class="c6 c26"><span class="c15 c24">[2]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c15">Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. &quot;Glove: Global vectors for word representation.&quot; </span><span class="c15">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</span><span class="c15">. 2014.</span></p><p class="c6 c26"><span class="c15 c24">&nbsp;[3]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c15">Laskar, Md Tahmid Rahman, Xiangji Huang, and Enamul Hoque. &quot;Contextualized embeddings based transformer encoder for sentence similarity modeling in answer selection task.&quot; </span><span class="c15">Proceedings of The 12th Language Resources and Evaluation Conference</span><span class="c18 c15">. 2020.</span></p><p class="c6 c26"><span class="c18 c15">&nbsp;[4]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Svyatkovskiy, Alexey, et al. &quot;Pythia: AI-assisted code completion system.&quot; Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. 2019.</span></p><p class="c6 c26"><span class="c15">&nbsp;[5]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Project CodeNet - IBM Developer.&quot; 5 May. 2021, </span><span class="c15"><a class="c39" href="https://www.google.com/url?q=https://developer.ibm.com/exchanges/data/all/project-codenet/&amp;sa=D&amp;source=editors&amp;ust=1671744182228670&amp;usg=AOvVaw39bvhDZKmnFZb2aGPub6sW">https://developer.ibm.com/exchanges/data/all/project-codenet/</a></span><span class="c18 c15">. Accessed 13 Feb. 2022.</span></p><p class="c6 c26"><span class="c15">&nbsp;[6]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Hindle, Abram, et al. &ldquo;On the Naturalness of Software.&rdquo; </span><span class="c15 c32">Communications of the ACM</span><span class="c18 c15">, vol. 59, no. 5, 2016, pp. 122&ndash;131., doi:10.1145/2902362. </span></p><p class="c6 c26"><span class="c15">&nbsp;[7]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Jurafsky, Daniel, and James H. Martin. &ldquo;Speech and Language Processing (3rd Ed. Draft) Dan Jurafsky and James H. Martin.&rdquo; </span><span class="c15 c32">Speech and Language Processing</span><span class="c18 c15">, web.stanford.edu/~jurafsky/slp3/. </span></p><p class="c6 c26"><span class="c15">&nbsp;[8]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Yang, Yixiao, and Chen Xiang. &ldquo;Improve Language Modelling for Code Completion through Learning General Token Repetition of Source Code.&rdquo; </span><span class="c15 c32">International Conferences on Software Engineering and Knowledge Engineering</span><span class="c18 c15">, 2019, doi:10.18293/seke2019-056. </span></p><p class="c6 c26"><span class="c15">&nbsp;[9]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Barath, Boris. &ldquo;ML Code Completion.&rdquo; </span><span class="c15 c32">Imperial.ac.uk</span><span class="c18 c15">, www.imperial.ac.uk/media/imperial-college/faculty-of-engineering/computing/public/1920-ug-projects/distinguished-projects/ML-Code-Completion.pdf. </span></p><p class="c6 c26"><span class="c15">[10]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Li, Jian, et al. &ldquo;Code Completion with Neural Attention and Pointer ... - IJCAI.&rdquo; </span><span class="c15 c32">Ijcai.org</span><span class="c18 c15">, 2018, www.ijcai.org/Proceedings/2018/0578.pdf. </span></p><p class="c6 c26"><span class="c15">[11]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Das, Subhasis, and Chinmayee Shah. &ldquo;Contextual Code Completion Using Machine Learning.&rdquo; </span><span class="c15 c32">Stanford.edu</span><span class="c18 c15">, web.stanford.edu/~chshah/files/contextual-code-completion.pdf.</span></p><p class="c6 c26"><span class="c18 c15">[12] Ashish Vaswani, et. al, &ldquo;Attention is all you need&rdquo;, 31st Conference on Neural Information Processing Systems (NIPS 2017). </span></p><p class="c6 c26"><span class="c18 c15">[13] Sauravmaheshkar. (2021, March 6). Auto-completion using N-Gram models. Kaggle. Retrieved April 28, 2022, from https://www.kaggle.com/sauravmaheshkar/auto-completion-using-n-gram-models </span></p><p class="c6 c21"><span class="c18 c15"></span></p><p class="c48 c21"><span class="c18 c15"></span></p><p class="c6 c26 c21"><span class="c18 c15"></span></p><p class="c6 c26 c21"><span class="c18 c15"></span></p><p class="c6 c26 c21"><span class="c15 c18"></span></p><p class="c21 c48"><span class="c18 c15"></span></p><p class="c6 c26 c21"><span class="c18 c15"></span></p><p class="c48 c21"><span class="c18 c15"></span></p><p class="c6 c26 c21"><span class="c18 c15"></span></p><p class="c48 c21"><span class="c18 c15"></span></p><p class="c21 c33"><span class="c18 c15"></span></p><div><p class="c21 c55"><span class="c11"></span></p><p class="c13 c28"><span class="c11"></span></p></div></body></html>